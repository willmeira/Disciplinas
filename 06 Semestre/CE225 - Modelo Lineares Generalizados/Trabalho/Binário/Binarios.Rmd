---
title: "Trabalho de dados Binários"
author: Laís Hoffmam, Simone Matsubara, Yasmin Fernandes, Willian Meira
date: '`r Sys.Date() `'
output:
  pdf_document:
    keep_tex: true
  html_document: 
    code_folding: hide
    number_sections: yes
    toc: yes
    toc_float: yes
  word_document: default
subtitle: "Acidentes de carro"
header-includes: \usepackage[brazil]{babel}
                 \usepackage{amsmath}
                 \usepackage{float}
                 \usepackage{bm}
#csl: ABNT_UFPR_2011.csl
#bibliography: refs.bib
---
```{r, include=FALSE}
library(lattice)
library(readxl)
library(readr)
library(tidyverse)
#library(xlsx)
library(MASS)
library(DAAG)
library(gridExtra)
library(corrplot)
library(carData)
library(car)
library(statmod)
library(effects)
library(ROCR)
library(hnp)
library(faraway)
library(ggplot2)
```

# 1. Base de Dados

**1.1 Descrição dos dados**

Os dados foram retirados do pacote "DAAG", sendo dados dos EUA, entre 1997-2002, de acidentes de carro relatados pela polícia nos quais há um evento prejudicial (pessoas ou propriedade) e do qual pelo menos um veículo foi rebocado.
Os dados são restritos aos ocupantes do banco da frente, incluem apenas um subconjunto das variáveis registradas e são restritos de outras maneiras também.


A base original possui uma base de dados com 26.217 observações nas 15 variáveis a seguir.

1 - **dvcat**: velocidades estimadas do impacto do acidente: 1-9km/h, 10-24, 25-39, 40-54, 55+
\newline 2 - **weight**: Pesos de observação
\newline 3 - **dead**: Classificação se sobreviveu ao acidente: 1 = sobreviveu ou 0 = morreu
\newline 4 - **airbag**: Se o carro possui airbag: com ou sem airbag
\newline 5 - **seatbelt**: uso do cinto de segurança: com ou sem cinto
\newline 6 - **frontal**: impacto do acidente: 0 = não frontal, 1 = impacto frontal
\newline 7 - **sex**: Sexo: 0 = Feminino ou 1 = Masculino
\newline 8 - **ageOFocc**: Idade dos ocupantes do veículo
\newline 9 - **yearacc**: Ano do acidente (1997-2002)
\newline 10 - **yearVeh**: Ano do veículo (1953-2003)
\newline 11 - **abcat**: Se Airbags foram acionados: deploy, nodeploy, unavail
\newline 12 - **occRole**: Posição do airbag acionado: driver, pass
\newline 13 - **deploy**: Airbag acionados: 0: Se não possuia airbag ou não foi acionado, 1: Um ou mais airbags foram acionados
\newline 14 - **injSeverity**: Gravidade do acidente: 0:none, 1 = Possível Lesão, 2:no incapacity, 3:incapacity, 4:killed; 5:unknown, 6:prior death
\newline 15 - **caseid**: Número do caso.

O objetivo da análise foi modelar a probalidade de sobrevivencia dos acidentes de carro da base "nassCD" sob a influência do airbag e outros elementos.

O escopo da análise tem como respota a variável "dead", que informa se o ocupante do veículo sobreviveu ou não após o acidente. As demais covariáveis serão explicativas, no entando, foi constatado, verificando os dados da base, que algumas delas são irrelevantes ou estão mal explicadas ("weight" e "caseid"). Foram retiradas também as variáveis "airbag", "ageOFocc", "yearVeh", "abcat" e "injSeverity", pois não convergiram ao rodar os modelos. 

Outro detalhe, devido ao número elevado de registros (mais de 26000 linhas), pegamos uma amostra de aproximadamente 10% do total de registros.


```{r, echo=FALSE, eval=TRUE, results="hide"}
## Carregando e ajustando a base de dados
#*********************************
dados <- read.csv('base_vivo_morto.csv',header = TRUE)
dados<-dados[,c(-1,-10)]
```

```{r, echo=FALSE, eval=TRUE, results="markup"}
dados$dvcat <- as.ordered(ifelse(dados$dvcat == '1-9km/h','01/09',
                          ifelse(dados$dvcat == '10-24','10/24',
                          ifelse(dados$dvcat == '25-39','25/39',
                          ifelse(dados$dvcat == '40-54','40/54','55+')))))
dados$dead <- as.factor(dados$dead)
dados$seatbelt <- as.factor(ifelse(dados$seatbelt == 'belted','Sim','Nao'))
dados$frontal <- as.factor(ifelse(dados$frontal == 1,'Sim','Nao'))
dados$sex <- as.factor(ifelse(dados$sex == 'm', 'Masc','Fem'))
dados$deploy<-as.factor(ifelse(dados$deploy == 1,'Sim','Nao'))
names(dados)<-c('veloc','sobrev','cinto','frontal','sexo','idade','ocupantes','abfunc')
```

```{r, echo=FALSE, eval=TRUE, results="markup"}
head(dados, 10)
```


# 2 Análise Descritiva

**2.1 Medidas de Resumo**

```{r, echo=FALSE, eval=TRUE, results="hide"}
summary(dados)
```

Nota-se na varável velocidade uma frequência maior de acidentes na faixa de 25-39 milhas.
A maioria estava com cinto de segurança e os acidentes foram a maioria frontais.

**2.2 Boxplot**

```{r,echo=FALSE, eval=TRUE, results="markup"}

g1<-ggplot(dados, aes(x=factor(sobrev), y=idade, color=factor(sobrev))) +  geom_boxplot()+ xlab('Idade')+ ylab('') + theme(legend.title=element_blank())

#grid.arrange(g5, ncol=2, nrow=1)
```

```{r,echo=FALSE, eval=TRUE, results="markup"}
g1
```



**2.3 Gráficos de frequencia**


```{r, echo=FALSE, eval=TRUE, results="hide"}
x11()
par(mfrow = c(2,2))
barplot(table(dados$sobrev,dados$veloc), beside=T, las = 1,
        xlab = 'Faixa de velocidade', legend = c('Óbitos','Vivos'))
barplot(table(dados$sobrev,dados$cinto), beside=T, las = 1,
        xlab = 'Cinto') 
barplot(table(dados$sobrev,dados$frontal), beside=T, las = 1,
        xlab = 'Frontal') 
barplot(table(dados$sobrev,dados$sexo), beside=T, las = 1,
        xlab = 'Sexo')
```


###Intuitivamente sabemos que para nosso escopo a variável idade não é significativa para o nosso modelo porém para comprovar adiante faremos um teste para evidênciar a irrelevancia da variável no modelo.


# 3. Ajuste do Modelo de Regressão


##**3.1 Ligação Logito**

Vamos ajustar um Modelo Linear Generalizado Binomial com função de ligação Logito. A expressão do modelo é dada por:

$ln (\frac{\pi_i}{1-\pi_i}) = \beta_0 + \beta_1 Veloc_i + \beta_2 Sobrev_i + \beta_3 AbFunc_i + \beta_4 Cinto_i + \beta_5 Frontal_i + \beta_6 Sexo_i + \beta_7 Idade_i + \beta_8 Ocupantes_i + \beta_9 Grav_i$


No R, o modelo é declarado da seguinte forma:


```{r, echo=FALSE, eval=TRUE, results="hide"}
ajuste1 <- glm(sobrev ~ .,family=binomial(link='logit'),data = dados)
```


##**3.2 Ligação Probito**

Vamos ajustar um Modelo Linear Generalizado Binomial com função de ligação Probito. A expressão do modelo é dada por:


$\phi^{-1} (\pi_i) = \beta_0 + \beta_1 Veloc_i + \beta_2 Sobrev_i + \beta_3 AbFunc_i + \beta_4 Cinto_i + \beta_5 Frontal_i + \beta_6 Sexo_i + \beta_7 Idade_i + \beta_8 Ocupantes_i + \beta_9 Grav_i$


No R, o modelo é declarado da seguinte forma:


```{r}
ajuste2 <- glm(sobrev ~ .,family=binomial(link = 'probit'),data = dados)
```


##**3.3 Ligação Complemento log-log**

Vamos ajustar um Modelo Linear Generalizado Binomial com função de ligação Complemento Log Log. A expressão do modelo é dada por:


$ln[-ln(1-\pi_i)] = \beta_0 + \beta_1 Veloc_i + \beta_2 Sobrev_i + \beta_3 AbFunc_i + \beta_4 Cinto_i + \beta_5 Frontal_i + \beta_6 Sexo_i + \beta_7 Idade_i + \beta_8 Ocupantes_i + \beta_9 Grav_i$


No R, o modelo é declarado da seguinte forma:


```{r}
ajuste3 <- glm(sobrev ~ .,family=binomial(link='cloglog'),data = dados)
```


##**3.4 Ligação Cauchy**

Vamos ajustar um Modelo Linear Generalizado Binomial com função de ligação Cauchy. A expressão do modelo é dada por:


$tan[\pi_i(\mu_i- 0,5)] = \beta_0 + \beta_1 Veloc_i + \beta_2 Sobrev_i + \beta_3 AbFunc_i + \beta_4 Cinto_i + \beta_5 Frontal_i + \beta_6 Sexo_i + \beta_7 Idade_i + \beta_8 Ocupantes_i + \beta_9 Grav_i$

No R, o modelo é declarado da seguinte forma:


```{r}
ajuste4 <- glm(sobrev ~ .,control=glm.control(epsilon = 1e-8, maxit = 42, 
                                           trace = FALSE), family=binomial(link='cauchit'),data = dados)
```


# 4. Escolha do Modelo

O critério de informação AIC pode também ser utilizado, porém o AIC penaliza o número de parâmetros do modelo. Como os modelos tem o mesmo número de parâmetros, o critério aponta para a mesma direção da verossimilhança pois todos são penalizados da mesma forma.




```{r, echo=FALSE, eval=TRUE, results="hide"}
selec <- data.frame(ajuste=c('logito', 'probito', 'cloglog', 'cauchy'),
                    aic=c(AIC(ajuste1), AIC(ajuste2), AIC(ajuste3), AIC(ajuste4)),
                    logLik=c(logLik(ajuste1),logLik(ajuste2),logLik(ajuste3),logLik(ajuste4)))
selec
```


O modelo que apresentou menor AIC e maior verossimilhança foi o modelo Binomial com função de ligação Cauchy.

# 5. Análise do Modelo Ajustado Selecionado


##**5.1 Resumo do Modelo**


```{r, echo=FALSE, eval=TRUE, results="hide"}
summary(ajuste4) 
```


LIneu
O resumo do modelo ajustado indica que as variáveis adesão marginal, nucléolos nus, cromatina branda, nucléolo normal e espessura do aglomerado estão associadas a uma maior probabilidade de tumor maligno, enquanto as demais variáveis não apresentam relação com a resposta.



##**5.2 Reajuste do Modelo**

Lineu
Como as covariáveis são altamente correlacionadas, é válido inserir as covariáveis uma a uma no modelo para verificar sua significância na presença das outras, tal como o realizado pelo algoritmo stepwise.

Sendo assim, o novo modelo fica da seguinte forma:


```{r, echo=TRUE, eval=TRUE, results="hide"}
ajuste4.1 <- step(ajuste4, direction = "both")
```


```{r, echo=FALSE, eval=TRUE, results="hide"}

summary(ajuste4.1)

selec2 <- data.frame(ajuste=c('aj4', 'aj4.1'),
                    aic=c(AIC(ajuste4), AIC(ajuste4.1)),
                    logLik=c(logLik(ajuste4),logLik(ajuste4.1)),
                    Dev=c(deviance(ajuste4),deviance(ajuste4.1)))

selec2
```


O resumo do novo modelo ajustado:



```{r}
anova(ajuste4, ajuste4.1, test = 'Chisq')
```



##**5.3 Análise de Resíduos**


```{r, echo=FALSE, eval=TRUE, results="hide"}

par(mfrow=c(2,2))
plot(ajuste4.1, 1:4)

par(mfrow=c(2,2))
plot(ajuste4, 1:4)


```


**5.4 Medidas de Influencia**


```{r}
influenceIndexPlot(ajuste4.1, vars=c("Cook"), main="Distância de Cook")
```


```{r}
influenceIndexPlot(ajuste4.1, vars=c("Studentized"), main="Resíduos Padronizados")
```


**5.5 Resíduos Quantílicos Aleatoriazados**


##**5.6 Gráfico Normal de Probabilidades com Envelope Simulado**

Lineu
O gráfico de resíduos simulados permite verificar a adequação do modelo ajustado mesmo que os resíduos não tenham uma aproximação adequada com a distribuição Normal. Neste tipo de gráfico espera-se, para um modelo bem ajustado, os pontos (resíduos) dispersos aleatoriamente entre os limites do envelope.

Deve-se ficar atento à presença de pontos fora dos limites do envelope ou ainda a pontos dentro dos limites porém apresentando padrões sistemáticos.

Vamos utilizar a função envelope implementada pelo professor Cesar Augusto Taconeli :

```{r, echo=FALSE, eval=TRUE, results="hide"}
envSim <- function(model, data, nsim = 100){
    dados <- na.omit(data)
    n <- .subset2(model, "df.null") + 1
    resM <- matrix(0, nrow = n, ncol = nsim)
    sim <- simulate(model, nsim)
    for (i in 1:nsim){
        dados$y <- .subset2(sim, i)
        mSim <- update(model, y ~ ., data = dados)
        resM[,i] <- sort.default(rstandard(mSim, type = 'deviance'), na.last = TRUE)
    }
    qS <- apply(resM, 1 , quantile, c(0.025, 0.5, 0.975), na.rm = TRUE)
    qN <- qnorm((1:n-0.5)/n)
    plot(rep(qN, 2), c(qS[1,], qS[3,]), type = 'n', xlab = 'Percentil da N(0,1)',
         ylab = 'Resíduos Padronizados', main = 'Gráfico Normal de Probabilidades')
    lines(qN, qS[1,], type = 'l')
    lines(qN, qS[2,], type = 'l', lty = 2, col = 4)
    lines(qN, qS[3,], type = 'l')
    points(qN, sort.default(rstandard(model, type = 'deviance'), na.last = TRUE), pch = 16, cex = 0.75)
}


envSim(model = ajuste4.1, data = ajuste4.1$data)
```

**5.7 Gráficos de Efeitos**


```{r, echo=FALSE, eval=TRUE, results="hide"}
plot(allEffects(ajuste4.1), type = 'response', main = '')
```


# 6. PREDIÇÃO


# 7. AVALIAÇÃO DO PODER PREDITIVO DO MODELO

Como temos uma base de tamanho razoável para fins preditivos, uma alternativa é separar a base em duas: uma para o ajuste do modelo, com 70% dos dados (com 477 observações) e outra para validação, com 30% (com 203 observações).


## **7.1 Divisão da Base de dados**

```{r}
set.seed(1909)
indices <- sample(1:680, size = 477) 
dadosajuste <- dados[indices,]
dadosvalid <- dados[-indices,]

```


## **7.2 Ponto de Corte**

Como estamos modelando a probabilidade de tumor maligno, vamos estabelecer o ponto de corte 0.5, isso é, se a probabilidade estimada for maior que este valor o tumor será classificado como maligno.
Vamos armazenar os valores preditos do modelo para os dados de validação:

```{r}
pred <- predict(ajuste4.1, newdata = dadosvalid, type = 'response')
corte <- ifelse(pred > 0.5, 'maligno', 'benigno')

```



**7.3 Sensibilidade e Especificidade**

Para fazer uso dos dados de validação, dois conceitos são necessários: sensibilidade e especificidade.

Define-se por sensibilidade a capacidade do modelo de detectar tumores malignos, ou seja, de classificar como malignos os tumores que de fato o são .

Já a especificidade é a capacidade do modelo de detectar classificar como benignos tumores verdadeiramente benignos.

A sensibilidade é dada por

```{r}
#sens <- dados[2,2]/sum(dados[,2])
#sens 
```


**7.4 Curva ROC**

**7.5 Outra Alternativa de validação**

# 8. REFERÊNCIAS



