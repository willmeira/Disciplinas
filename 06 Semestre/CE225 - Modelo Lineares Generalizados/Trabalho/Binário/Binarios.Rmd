---
title: "Trabalho de dados Binários"
author: Laís Hoffmam, Simone Matsubara, Yasmin Fernandes, Willian Meira
date: '`r Sys.Date() `'
output:
  pdf_document:
    keep_tex: true
  html_document: 
    code_folding: hide
    number_sections: yes
    toc: yes
    toc_float: yes
  word_document: default
subtitle: "Acidentes de carro"
header-includes: \usepackage[brazil]{babel}
                 \usepackage{amsmath}
                 \usepackage{float}
                 \usepackage{bm}
#csl: ABNT_UFPR_2011.csl
#bibliography: refs.bib
---
```{r, include=FALSE}
library(lattice)
library(MASS)
library(DAAG)
library(gridExtra)
library(corrplot)
library(carData)
library(car)
library(statmod)
library(effects)
library(ROCR)
library(hnp)
library(faraway)
library(ggplot2)
```

# 1. Base de Dados

**1.1 Descrição dos dados**

Os dados foram retirados do pacote "DAAG", sendo dados dos EUA, entre 1997-2002, de acidentes de carro relatados pela polícia nos quais há um evento prejudicial (pessoas ou propriedade) e do qual pelo menos um veículo foi rebocado.
Os dados são restritos aos ocupantes do banco da frente, incluem apenas um subconjunto das variáveis registradas e são restritos de outras maneiras também.


A base original possui uma base de dados com 26.217 observações nas 15 variáveis a seguir.

1 - **veloc**: velocidades estimadas do impacto do acidente: 1-9km/h, 10-24, 25-39, 40-54, 55+
\newline 2 - **pesos**: Pesos de observação
\newline 3 - **sobrev**: Classificação se sobreviveu ao acidente: 1 = sobreviveu ou 0 = morreu
\newline 4 - **airbag**: Se o carro possui airbag: com ou sem airbag
\newline 5 - **cinto**: uso do cinto de segurança: com ou sem cinto
\newline 6 - **frontal**: impacto do acidente: 0 = não frontal, 1 = impacto frontal
\newline 7 - **sexo**: Sexo: 0 = Feminino ou 1 = Masculino
\newline 8 - **idade**: Idade dos ocupantes do veículo
\newline 9 - **anoaci**: Ano do acidente (1997-2002)
\newline 10 - **anovei**: Ano do veículo (1953-2003)
\newline 11 - **airbagcat**: Se Airbags foram acionados: deploy, nodeploy, unavail
\newline 12 - **ocupantes**: Posição do airbag acionado: driver, pass
\newline 13 - **abfunc**: Airbag acionados: 0: Se não possuia airbag ou não foi acionado, 1: Um ou mais airbags foram acionados
\newline 14 - **grav**: Gravidade do acidente: 0:none, 1 = Possível Lesão, 2:no incapacity, 3:incapacity, 4:killed; 5:unknown, 6:prior death
\newline 15 - **numcaso**: Número do caso.

No entanto, escolhemos analisar os dados do ano do acidente de 1997, e retirar as variaveis weight, abcat, airbag e caseid. 

O objetivo da análise foi modelar a probalidade de sobrevivencia dos acidentes de carro da base "nassCD" sob a influência do airbag e outros elementos.


```{r, include=FALSE}
## Carregando e ajustando a base de dados
#*********************************
data("nassCDS")
dados <- nassCDS
dados<-subset(dados,yearacc=="1997")

#selecionando covariáveis
dados <-nassCDS[,c(-2,-4,-9,-10,-11,-15)]
summary(dados)

#ajustando as variáveis
dados$dvcat <- as.numeric(ifelse(dados$dvcat == '1-9km/h',01-09,
                                 ifelse(dados$dvcat == '10-24',17,
                                        ifelse(dados$dvcat == '25-39',32,
                                               ifelse(dados$dvcat == '40-54',47,55)))))
dados$dead <- as.numeric(ifelse(dados$dead == 'alive',1,0))
dados$seatbelt <- as.numeric(ifelse(dados$seatbelt == 'belted',1,0))
dados$frontal <- as.numeric(ifelse(dados$frontal == 1,1,0))
dados$sex <- as.numeric(ifelse(dados$sex == 'm', 1,0))
dados$occRole <- as.numeric(ifelse(dados$occRole == 'driver',0,1))
dados$deploy<-as.numeric(ifelse(dados$deploy == 1,1,0))
dados$cinto
dados$injSeverity<-as.ordered(dados$injSeverity)
dados2<-na.omit(dados)

vivos<-dados[dados$dead==1,]
mortos<-dados[dados$dead==0,]

sum(vivos$dead==1)
sum(vivos$dead==0)
sum(mortos$dead==1)
sum(mortos$dead==0)
n<-1180
dim(vivos)

set.seed(222)
vivos2<-vivos[sample(nrow(vivos),size=1180,replace=FALSE),]
dim(vivos2)

total <- rbind(vivos2, mortos)
names(total)<-c('veloc','sobrev','cinto','frontal','sexo',
                 'idade','ocupantes','abfunc','grav')
```


# 2 Análise Descritiva

**2.1 Medidas de Resumo**

```{r}
summary(total)
```

Nota-se na varável velocidade uma frequência maior de acidentes na faixa de 25-39 milhas.
A maioria estava com cinto de segurança e os acidentes foram a maioria frontais.

**2.3 Histogramas**

```{r, echo=FALSE, eval=TRUE, results="hide"}
par(mfrow = c(3,3))
hist(total$sobrev,breaks = 2,main = "0 morreu 1 sobreviveu " ,xlab = "sobreviveu" )
hist(total$abfunc, breaks = 2,main = "0 NÃO 1 SIM " ,xlab =  "Airbag Funcionou")
hist(total$cinto, breaks = 2,main = "0 NÃO 1 SIM" ,xlab =  "Possui Cinto")
hist(total$frontal, breaks = 2,main = "0 NÃO 1 SIM" ,xlab =  "Acidente frontal ")
hist(total$sexo,breaks = 2,main = "1 HOMEM 0 MULHER" ,xlab =  "Sexo")
hist(total$ocupantes,breaks = 2,main = "1 SIM 0 NÃO" ,xlab =  "2 passageiros na frente")
```



**2.4 Distribuição**


```{r,echo=FALSE, eval=TRUE, results="hide"}
g1<-ggplot(total, aes(x=factor(sobrev), y=veloc, color=factor(sobrev))) +  geom_boxplot()+ xlab('Velocidade')+ ylab('') + theme(legend.title=element_blank())

g5<-ggplot(total, aes(x=factor(sobrev), y=idade, color=factor(sobrev))) +  geom_boxplot()+ xlab('Idade')+ ylab('') + theme(legend.title=element_blank())

grid.arrange(g1,g5, ncol=2, nrow=1)

```

```{r}
x11()
par(mfrow = c(1,3))
barplot(table(total$sobrev,total$cinto), beside=T, ylim=c(0,5000), las = 1,
        xlab = 'Cinto', ylab = 'Sovreviventes', legend = c('Não','Sim'))

barplot(table(total$sobrev,total$frontal), beside=T, ylim=c(0,2500), las = 1,
        xlab = 'Frontal', ylab = 'Sobreviventes', legend = c('Não','Sim')) 
barplot(table(total$sobrev,total$sexo), beside=T, ylim=c(0,2500), las = 1,
        xlab = 'Sexo', ylab = 'Sobreviventes', legend = c('Não','Sim')) 

```



###Intuitivamente sabemos que para nosso escopo a variável idade não é significativa para o nosso modelo porém para comprovar adiante faremos um teste para evidênciar a irrelevancia da variável no modelo.


# 3. Ajuste do Modelo de Regressão


##**3.1 Ligação Logito**

Vamos ajustar um Modelo Linear Generalizado Binomial com função de ligação Logito. A expressão do modelo é dada por:

$ln (\frac{\pi_i}{1-\pi_i}) = \beta_0 + \beta_1 Veloc_i + \beta_2 Sobrev_i + \beta_3 AbFunc_i + \beta_4 Cinto_i + \beta_5 Frontal_i + \beta_6 Sexo_i + \beta_7 Idade_i + \beta_8 Ocupantes_i + \beta_9 Grav_i$


No R, o modelo é declarado da seguinte forma:


```{r}
ajuste1 <- glm(sobrev ~ .,family=binomial(link='logit'),data = total)
```


##**3.2 Ligação Probito**

Vamos ajustar um Modelo Linear Generalizado Binomial com função de ligação Probito. A expressão do modelo é dada por:


$\phi^{-1} (\pi_i) = \beta_0 + \beta_1 Veloc_i + \beta_2 Sobrev_i + \beta_3 AbFunc_i + \beta_4 Cinto_i + \beta_5 Frontal_i + \beta_6 Sexo_i + \beta_7 Idade_i + \beta_8 Ocupantes_i + \beta_9 Grav_i$


No R, o modelo é declarado da seguinte forma:


```{r}
ajuste2 <- glm(sobrev ~ .,family=binomial(link = 'probit'),data = total)
```


##**3.3 Ligação Complemento log-log**

Vamos ajustar um Modelo Linear Generalizado Binomial com função de ligação Complemento Log Log. A expressão do modelo é dada por:


$ln[-ln(1-\pi_i)] = \beta_0 + \beta_1 Veloc_i + \beta_2 Sobrev_i + \beta_3 AbFunc_i + \beta_4 Cinto_i + \beta_5 Frontal_i + \beta_6 Sexo_i + \beta_7 Idade_i + \beta_8 Ocupantes_i + \beta_9 Grav_i$


No R, o modelo é declarado da seguinte forma:


```{r}
ajuste3 <- glm(sobrev ~ .,family=binomial(link='cloglog'),data = total)
```


##**3.4 Ligação Cauchy**

Vamos ajustar um Modelo Linear Generalizado Binomial com função de ligação Cauchy. A expressão do modelo é dada por:


$tan[\pi_i(\mu_i- 0,5)] = \beta_0 + \beta_1 Veloc_i + \beta_2 Sobrev_i + \beta_3 AbFunc_i + \beta_4 Cinto_i + \beta_5 Frontal_i + \beta_6 Sexo_i + \beta_7 Idade_i + \beta_8 Ocupantes_i + \beta_9 Grav_i$

No R, o modelo é declarado da seguinte forma:


```{r}
ajuste4 <- glm(sobrev ~ .,control=glm.control(epsilon = 1e-8, maxit = 42, 
                                           trace = FALSE), family=binomial(link='cauchit'),data = total)
```


# 4. Escolha do Modelo

O critério de informação AIC pode também ser utilizado, porém o AIC penaliza o número de parâmetros do modelo. Como os modelos tem o mesmo número de parâmetros, o critério aponta para a mesma direção da verossimilhança pois todos são penalizados da mesma forma.




```{r, echo=FALSE, eval=TRUE, results="hide"}
selec <- data.frame(ajuste=c('logito', 'probito', 'cloglog', 'cauchy'),
                    aic=c(AIC(ajuste1), AIC(ajuste2), AIC(ajuste3), AIC(ajuste4)),
                    logLik=c(logLik(ajuste1),logLik(ajuste2),logLik(ajuste3),logLik(ajuste4)))
selec
```


O modelo que apresentou menor AIC e maior verossimilhança foi o modelo Binomial com função de ligação Cauchy.

# 5. Análise do Modelo Ajustado Selecionado


##**5.1 Resumo do Modelo**


```{r, echo=FALSE, eval=TRUE, results="hide"}
summary(ajuste4) 
```


LIneu
O resumo do modelo ajustado indica que as variáveis adesão marginal, nucléolos nus, cromatina branda, nucléolo normal e espessura do aglomerado estão associadas a uma maior probabilidade de tumor maligno, enquanto as demais variáveis não apresentam relação com a resposta.



##**5.2 Reajuste do Modelo**

Lineu
Como as covariáveis são altamente correlacionadas, é válido inserir as covariáveis uma a uma no modelo para verificar sua significância na presença das outras, tal como o realizado pelo algoritmo stepwise.

Sendo assim, o novo modelo fica da seguinte forma:


```{r, echo=TRUE, eval=TRUE, results="hide"}
ajuste4.1 <- step(ajuste4, direction = "both")
```


```{r, echo=FALSE, eval=TRUE, results="hide"}

summary(ajuste4.1)

selec2 <- data.frame(ajuste=c('aj4', 'aj4.1'),
                    aic=c(AIC(ajuste4), AIC(ajuste4.1)),
                    logLik=c(logLik(ajuste4),logLik(ajuste4.1)),
                    Dev=c(deviance(ajuste4),deviance(ajuste4.1)))

selec2
```


O resumo do novo modelo ajustado:



```{r}
anova(ajuste4, ajuste4.1, test = 'Chisq')
```



##**5.3 Análise de Resíduos**


```{r, echo=FALSE, eval=TRUE, results="hide"}

par(mfrow=c(2,2))
plot(ajuste4.1, 1:4)

par(mfrow=c(2,2))
plot(ajuste4, 1:4)


```


**5.4 Medidas de Influencia**


```{r}
influenceIndexPlot(ajuste4.1, vars=c("Cook"), main="Distância de Cook")
```


```{r}
influenceIndexPlot(ajuste4.1, vars=c("Studentized"), main="Resíduos Padronizados")
```


**5.5 Resíduos Quantílicos Aleatoriazados**


##**5.6 Gráfico Normal de Probabilidades com Envelope Simulado**

Lineu
O gráfico de resíduos simulados permite verificar a adequação do modelo ajustado mesmo que os resíduos não tenham uma aproximação adequada com a distribuição Normal. Neste tipo de gráfico espera-se, para um modelo bem ajustado, os pontos (resíduos) dispersos aleatoriamente entre os limites do envelope.

Deve-se ficar atento à presença de pontos fora dos limites do envelope ou ainda a pontos dentro dos limites porém apresentando padrões sistemáticos.

Vamos utilizar a função envelope implementada pelo professor Cesar Augusto Taconeli :

```{r, echo=FALSE, eval=TRUE, results="hide"}
envSim <- function(model, data, nsim = 100){
    dados <- na.omit(data)
    n <- .subset2(model, "df.null") + 1
    resM <- matrix(0, nrow = n, ncol = nsim)
    sim <- simulate(model, nsim)
    for (i in 1:nsim){
        dados$y <- .subset2(sim, i)
        mSim <- update(model, y ~ ., data = dados)
        resM[,i] <- sort.default(rstandard(mSim, type = 'deviance'), na.last = TRUE)
    }
    qS <- apply(resM, 1 , quantile, c(0.025, 0.5, 0.975), na.rm = TRUE)
    qN <- qnorm((1:n-0.5)/n)
    plot(rep(qN, 2), c(qS[1,], qS[3,]), type = 'n', xlab = 'Percentil da N(0,1)',
         ylab = 'Resíduos Padronizados', main = 'Gráfico Normal de Probabilidades')
    lines(qN, qS[1,], type = 'l')
    lines(qN, qS[2,], type = 'l', lty = 2, col = 4)
    lines(qN, qS[3,], type = 'l')
    points(qN, sort.default(rstandard(model, type = 'deviance'), na.last = TRUE), pch = 16, cex = 0.75)
}


envSim(model = ajuste4.1, data = ajuste4.1$data)
```

**5.7 Gráficos de Efeitos**


```{r, echo=FALSE, eval=TRUE, results="hide"}
plot(allEffects(ajuste4.1), type = 'response', main = '')
```


# 6. PREDIÇÃO


# 7. AVALIAÇÃO DO PODER PREDITIVO DO MODELO

Como temos uma base de tamanho razoável para fins preditivos, uma alternativa é separar a base em duas: uma para o ajuste do modelo, com 70% dos dados (com 477 observações) e outra para validação, com 30% (com 203 observações).


## **7.1 Divisão da Base de dados**

```{r}
set.seed(1909)
indices <- sample(1:680, size = 477) 
dadosajuste <- total[indices,]
dadosvalid <- total[-indices,]

```


## **7.2 Ponto de Corte**

Como estamos modelando a probabilidade de tumor maligno, vamos estabelecer o ponto de corte 0.5, isso é, se a probabilidade estimada for maior que este valor o tumor será classificado como maligno.
Vamos armazenar os valores preditos do modelo para os dados de validação:

```{r}
pred <- predict(ajuste4.1, newdata = dadosvalid, type = 'response')
corte <- ifelse(pred > 0.5, 'maligno', 'benigno')

```



**7.3 Sensibilidade e Especificidade**

**7.4 Curva ROC**

**7.5 Outra Alternativa de validação**

# 8. REFERÊNCIAS



