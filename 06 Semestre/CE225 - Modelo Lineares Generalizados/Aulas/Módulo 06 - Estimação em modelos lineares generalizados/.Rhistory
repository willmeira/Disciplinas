require(coefplot)
require(sandwich)
install.packages("sandwich")
require(sandwich)
require(lmtest)
dados <- read.csv2('https://docs.ufpr.br/~taconeli/CE22517/sinistros.csv')[,-1]
dados
head(dados, 10) ### Dez primeiras linhas da base.
dados <- read.csv2('https://docs.ufpr.br/~taconeli/CE22517/sinistros.csv')[,-1]
require(rattle.data)
require(statmod)
require(ISLR)
require(car)
require(hnp)
require(pscl)
require(coefplot)
require(effects)
require(sandwich)
require(lmtest)
dados <- read.csv2('https://docs.ufpr.br/~taconeli/CE22517/sinistros.csv')[,-1]
dados <- read.csv2('sinistros.csv')[,-1]
dados <- read.csv('sinistros.csv')[,-1]
dados <- read.csv('sinistros.csv',header = TRUE)[,-1]
setwd("/tmp/mozilla_willmeira0")
dados <- read.csv('sinistros.csv',header = TRUE)[,-1]
dados <- read.csv('sinistros.csv',header = TRUE)
setwd("~/Documentos/Git/disciplinas/06 Semestre/CE225 - Modelo Lineares Generalizados/Aulas/Módulo 06 - Estimação em modelos lineares generalizados")
dados <- read.csv('sinistros.csv',header = TRUE)
dados <- read.csv('sinistros.csv',header = TRUE)[,-1]
dados
dados <- read.csv('sinistros.csv',header = TRUE)
dados
dados <- read.csv2('sinistros.csv',header = TRUE)
dados
head(dados, 10) ### Dez primeiras linhas da base.
summary(dados) ### Algumas descritivas dos dados.
x11(width = 12, height = 10)
par(las = 1, mar = c(5,4.5,2,2), cex = 1.4)
plot(table(dados$claims), col = 'blue', lwd = 5, xlab = 'N?mero de sinistros',
ylab = 'Frequ?ncia', xaxt = 'n')
axis(1, 0:9)
d1 <- with(dados, data.frame(table(sexo, factor(claims, levels = 0:9))))
names(d1) <- c("sexo","claims","Freq")
ggplot(data = d1, aes(x = claims, y = Freq)) + geom_bar(stat = "identity") +
facet_wrap(~ sexo) + theme_bw(base_size = 18) + ylab("Frequ?ncia") + xlab('N?mero de sinistros')
ggplot(data = d1, aes(x = claims, y = Freq)) + geom_bar(stat = "identity") +
facet_wrap(~ sexo) + theme_bw(base_size = 18) + ylab("Frequ?ncia") + xlab('N?mero de sinistros')
x11()
d2 <- with(dados, data.frame(table(usop, factor(claims, levels = 0:9))))
names(d2) <- c("usop","claims","Freq")
ggplot(data = d2, aes(x = claims, y = Freq)) + geom_bar(stat = "identity")+
facet_wrap(~ usop) + theme_bw(base_size = 18) + ylab("Frequ?ncia") + xlab('N?mero de sinistros')
ggplot(data = dados, aes(x = anosest, y = claims)) + geom_jitter() +
theme_bw(base_size = 18) + ylab("N?mero de sinistros") + xlab('Anos de estudo') +
geom_smooth(method = 'loess')
ggplot(data = d2, aes(x = claims, y = Freq)) + geom_bar(stat = "identity")+
facet_wrap(~ usop) + theme_bw(base_size = 18) + ylab("Frequ?ncia") + xlab('N?mero de sinistros')
ggplot(data = dados, aes(x = idade, y = claims)) + geom_jitter() +
theme_bw(base_size = 18) + ylab("N?mero de sinistros") + xlab('Idade') +
geom_smooth(method = 'loess')
ggplot(data = dados, aes(x = anosest, y = claims)) + geom_jitter() +
theme_bw(base_size = 18) + ylab("N?mero de sinistros") + xlab('Anos de estudo') +
geom_smooth(method = 'loess')
ggplot(data = dados, aes(x = idade, y = claims)) + geom_jitter() +
theme_bw(base_size = 18) + ylab("N?mero de sinistros") + xlab('Idade') +
geom_smooth(method = 'loess')
x11(width = 10, height = 10)
ajuste1 <- lm(claims ~ idade + sexo + usop + anosest, data=dados)
par(mfrow=c(2,2), cex = 1.4, las = 1, mar = c(4,4,2,2))
plot(ajuste1)
ajuste2 <- glm(claims ~ idade + sexo + usop + anosest, family = poisson(link = 'log'),
data = dados)
coefficients(ajuste2)
head(model.matrix(ajuste2))
fitted(ajuste2)
predict(ajuste2)
ajuste2$iter
ajuste2$weights
vcov(ajuste2)
### matriz de vari?ncias e covari?ncias estimada para os par?metros de
### regress?o.
### Para fins dis?ticos, vamos estimar o par?metro de dispers?o. Primeiro
### usando a estat?stica X^2 de Pearson.
mu <- fitted(ajuste2)
y <- dados$claims
df <- ajuste2$df.residual
phi <- sum(((y-mu)^2)/mu)/df
phi
par(cex = 1.4, las = 1)
plot(B_idade_grid, vet_logLik, type = 'b', pch = 20, xlav = 'B_idade', ylab = 'Log-verossimilhan?a')
head(model.matrix(ajuste2))
### Matriz do modelo.
fitted(ajuste2)
### Valores ajustados pelo modelo, para os 500 indiv?duos da base, na escala
### da resposta.
predict(ajuste2)
### Valores ajustados pelo modelo, para os 500 indiv?duos da base, na escala
### do preditor.
### Recomendo acessar a documenta??o da fun??o predict.glm para conferir
### as op??es. Voltaremos a ela adiante.
ajuste2$iter
### Foram necess?rias cinco itera??es at? a converg?ncia no processo de estima??o.
ajuste2$weights
### Esses s?o os pesos calculados na ?ltima itera??o do algoritmo de estima??o.
summary(ajuste2)
### Um resumo mais detalhado do modelo ajustado.
vcov(ajuste2)
### matriz de vari?ncias e covari?ncias estimada para os par?metros de
### regress?o.
### Para fins dis?ticos, vamos estimar o par?metro de dispers?o. Primeiro
### usando a estat?stica X^2 de Pearson.
mu <- fitted(ajuste2)
y <- dados$claims
df <- ajuste2$df.residual
phi <- sum(((y-mu)^2)/mu)/df
phi
### Agora usando a deviance.
dev <- ajuste2$deviance
phi <- dev/df
phi
########################################################################
########################################################################
########################################################################
### Infer?ncias e qualidade do ajuste.
########################################################################
### Teste da raz?o de verossimilhan?as.
### Vamos testar algumas hip?teses usando o TRV. Vamos denotar por B_...
### os par?metros (betas) do modelo.
### Hip?tese 1- H0: BsexoMasc = 0.
ajH0 <- glm(claims ~ idade + usop + anosest, family = poisson(link = 'log'),
data = dados)
### ou, de forma abreviada:
ajH0 <- update(ajuste2, claims ~.-sexo)
### Na m?o:
### Vamos extrair as log-verossimilhan?as maximizadas sob os dois modelos:
l0 <- as.numeric(logLik(ajH0)); l0
l1 <- as.numeric(logLik(ajuste2)); l1
### A estat?stica do teste da raz?o de verossimilhan?as fica dada por:
Lambda <- -2*(l0-l1); Lambda
### Como estamos testando um ?nico par?metro, a distribui??o de refer?ncia
### para o teste ? a qui-quadrado com um grau de liberdade. Vamos obter o
### valor cr?tico para um n?vel de signific?ncia de 5%:
qchisq(0.05, df = 1, lower.tail = FALSE)
### Como o valor da estat?stica do teste n?o excede o valor cr?tico, a
### hip?tese nula (n?o efeito de sexo) n?o ? rejeitada ao n?vel de signific?ncia
### de 5%. Vamos calcular o p-valor do teste.
pchisq(Lambda, df = 1, lower.tail = FALSE)
### Usando a fun??o anova:
anova(ajH0, ajuste2, test = 'Chisq')
### Exerc?cio: Aplicar o teste da raz?o de verossimilhan?as no teste da
### hip?tese nula H0: B_sexoMasc = B_anosest = 0.
### Teste de Wald.
### O resultado do teste de Wald, para cada par?metro, j? ? apresentado
### no summary do modelo. Vamos aplicar o m?todo de Wald para testar a
### hip?tese H0: B_sexoMasc = B_anosest = 0.
### Na m?o. Come?amos extraindo estimativas pontuais e a parte da matriz
### de vari?ncias e covari?ncias referentes aos dois par?metros sob teste.
B0 <- matrix(coef(ajuste2)[c(3,5)]); B0
VarB0 <- vcov(ajuste2)[c(3,5),c(3,5)]; VarB0
### Agora, vamos calcular a estat?stica do teste de Wald:
W <- t(B0) %*% solve(VarB0) %*% B0
W
### Como estamos testando dois par?metro, a distribui??o de refer?ncia
### para o teste ? a qui-quadrado com dois graus de liberdade. Vamos obter o
### valor cr?tico para um n?vel de signific?ncia de 5%:
qchisq(0.05, df = 2, lower.tail = FALSE)
### Como o valor da estat?stica do teste n?o excede o valor cr?tico, a
### hip?tese nula (n?o efeito de sexo e escolaridade) n?o ? rejeitada ao
### n?vel de signific?ncia de 5%. Vamos calcular o p-valor do teste.
pchisq(W, df = 2, lower.tail = FALSE)
### Agora, vamos usar a fun??o waldtest do pacote lmtest:
ajH0 <- update(ajuste2, claims ~.-sexo - anosest)
waldtest(ajH0, ajuste2, test = 'Chisq')
### Exerc?cio: Aplicar o m?todo de Wald no teste da hip?tese nula
### H0: B_sexoMasc = B_idade = 0.
########################################################################
### Intervalos de confian?a
### Agora, intervalos de confian?a. Come?ando pelo m?todo de Wald. Vamos
### obter um intervalo de 95% de confian?a para B_idade:
Bchap <- coef(ajuste2)[2]; Bchap
VBchap <- vcov(ajuste2)[2,2]; VBchap
ICB_idade <- c(Bchap - 1.96 * sqrt(VBchap), Bchap + 1.96 * sqrt(VBchap))
ICB_idade
### Como alternativa, podemos usar a fun??o confint.default:
confint.default(ajuste2, parm = "idade", level = 0.95)
confint.default(ajuste2, parm = "idade", level = 0.99)
confint.default(ajuste2, level = 0.95)
### Se quisermos um IC(95%) para exp(B_idade), basta exponenciar os limites
### do IC obtido para B_idade:
exp(ICB_idade)
### Procedimento semelhante valeria para qualquer outra fun??o mon?tona
### de B_idade.
### Vamos ilustrar agora a constru??o do IC baseado no perfil da verossimilhan?a.
### Para isso, precisamos obter o valor da (log) verossimilhan?a maximizada
### para um grid de valores de
B_idade_grid <- seq(-0.08, -0.035, length.out = 20)
### Agora, para cada valor de B_idade em B_idade_grid vamos ajustar novamente
### o glm, mas fixando B_idade. Para cada ajuste vamos extrair o valor da
### log-verossimilhan?a maximizada. Antes, vamos aplicar esse procedimento
### a um particular valor de B_idade, para fins ilustrativos. Tomemos
### B_idade=-0.05.
ajuste <- glm(claims ~ offset(-0.05 * idade) + usop + anosest + sexo, family = poisson(link = 'log'),
data = dados)
logLik(ajuste)
### log-verossimilhan?a maximizada para B_idade=-0.05. Agora, vamos aplicar
### igual procedimento para o grid de valores de B_idade.
vet_logLik <- numeric()
for(i in 1:length(B_idade_grid)){
B_idade <- B_idade_grid[i]
ajuste <- glm(claims ~ offset(B_idade * idade) + usop + anosest + sexo, family = poisson(link = 'log'),
data = dados)
vet_logLik[i] <- logLik(ajuste)
}
par(cex = 1.4, las = 1)
plot(B_idade_grid, vet_logLik, type = 'b', pch = 20, xlav = 'B_idade', ylab = 'Log-verossimilhan?a')
abline(h = logLik(ajuste2) - 3.84/2)
plot(allEffects(ajuste2)) ### Escala do link.
plot(allEffects(ajuste2), type = 'response') ### Escala da resposta.
x0 <- matrix(c(1, 30, 1, 1, 10))
x0 ### Vetor de covari?veis. o primeiro termo corresponde ao intercepto.
betas <- matrix(coef(ajuste2))
betas
t(x0) %*% betas ### Estimativa na escala do preditor (log(mu)).
exp(t(x0) %*% betas) ### Estimativa na escala da m?dia. Assim, para o perfil
### de segurado considerado, estima-se, em m?dia, 3.11 sinistros.
predict(ajuste2, newdata = data.frame(idade = 30, usop = 'Estrada',
sexo = 'Masc', anosest = 10))
### Por default, o R retorna a predi??o na escala do link. Para obter a
### estimativa da m?dia devemos aplicar a inversa da fun??o de liga??o:
predict(ajuste2, newdata = data.frame(idade = 30, usop = 'Estrada', sexo = 'Masc',
anosest = 10), type = 'response')
### Agora, na escala da m?dia, ou da resposta.
dpred <- data.frame(idade = c(30,30,60,60),
usop = c('Estrada','Cidade','Estrada','Cidade'),
sexo = c('Masc', 'Fem', 'Fem', 'Masc'),
anosest = c(5, 7, 12, 15))
mu_est <- predict(ajuste2, newdata = dpred, type = 'response')
dpred$mu <- mu_est
rownames(dpred) <- c('Perfil 1', 'Perfil 2', 'Perfil 3', 'Perfil 4')
dpred
### Estimativas para o n?mero esperado de sinistros em cinco anos para os
### quatro perfis de segurados.
### Vamos ver a distribui??o de probabilidades estimada para cada perfil.
ajusteNull <- glm(claims ~ 1, family = poisson(link = 'log'), data = dados)
summary(ajusteNull)
logLik(ajusteNull) ### log verossimilhan?a maximizada.
deviance(ajusteNull) ### deviance.
### correspondentes aos 500 indiv?duos da base.
pred_base <- predict(ajuste2, type = 'link', se.fit = TRUE)
ic <- cbind(pred_base$fit - 1.96 * pred_base$se.fit, pred_base$fit + 1.96 * pred_base$se.fit)
data.frame(dados[,1:4], exp(pred_base$fit), exp(ic))
### Base de dados acompanhada das estimativas para a frequ?ncia m?dia de
### sinistros e IC(95%).
########################################################################
########################################################################
########################################################################
### An?lise de deviance
### Modelo nulo - modelo s? com intercepto (um ?nico par?metro, comum a
### todas as observa??es)
ajusteNull <- glm(claims ~ 1, family = poisson(link = 'log'), data = dados)
summary(ajusteNull)
logLik(ajusteNull) ### log verossimilhan?a maximizada.
deviance(ajusteNull) ### deviance.
### Modelo saturado - modelo com n par?metros (um para cada observa??o)
obs <- factor(1:nrow(dados))
ajusteSat <- glm(claims ~ obs, family=poisson(link='log'),data=dados)
logLik(ajusteSat) ### log verossimilhan?a maximizada.
deviance(ajusteSat) ### deviance.
### Para o modelo ajustado com as quatro covari?veis:
logLik(ajuste2)
deviance(ajuste2)
### An?lise de deviance
anova(ajuste2, test='Chisq')
### Repare na sequ?ncia de testes que s?o realizados:
### 1- Inclus?o de idade ao modelo nulo (altamente significativa);
### 2- Inclus?o de sexo ao modelo com idade (n?o significativa);
### 3- Inclus?o de uso principal ao modelo com idade e sexo (altamente significativa);
### 4- Inclus?o de anos de estudo ao modelo com as demais vari?veis (n?o significativa).
Anova(ajuste2, test = 'LR')
### Repare na sequ?ncia de testes que s?o realizados:
### 1- Inclus?o de idade ao modelo com as demais tr?s vari?veis (altamente significativa);
### 2- Inclus?o de sexo ao modelo com as demais tr?s vari?veis (n?o significativa);
### 3- Inclus?o de uso principal ao modelo com as demais tr?s vari?veis (altamente significativa);
### 4- Inclus?o de anos de estudo ao modelo com as demais tr?s vari?veis (n?o significativa).
### Experimente entrar na fun??o glm com as vari?veis em outra ordem e
### usar anova e Anova. Observe o que muda.
drop1(ajuste2,test = 'Chisq')
### Elimina uma vari?vel por vez do modelo e testa a exclus?o da vari?vel
### via TRV. (similar a Anova)
### N?o se verifica altera??o significativa no ajuste resultante da exclus?o
### do sexo, nem da exclus?o dos anos de estudo.
### Para as outras duas, h? fortes evid?ncias que idade e uso principal
### estejam relacionadas ao n?mero de sinistros.
### Vamos explorar um pouco mais a parte de testes de hip?teses. Novamente,
### vamos testar o efeito de escolaridade e sexo, conjuntamente.
ajuste2_rest <- update(ajuste2, ~.-sexo-anosest)
### Modelo sob a restri??o.
anova(ajuste2_rest, ajuste2, test = 'Chisq')
### N?o h? efeito significativo de escolaridade e sexo. Podemos remov?-las
### do modelo ajustado. Adicionalmente, vamos avaliar se h? efeito de
### intera??o entre as vari?veis remanescentes (uso principal e idade).
ajuste2_int <- update(ajuste2_rest, ~.+idade:usop)
anova(ajuste2_rest, ajuste2_int, test = 'Chisq')
### O efeito de intera??o ? significativo. Fica como exerc?cio explorar
### esse ajuste (escrever a express?o do modelo ajustado, apresentar
### algumas infer?ncias e interpreta??es, fazer predi??es). Apenas adiantando,
### segue o resumo do ajuste.
summary(ajuste2_int)
########################################################################
########################################################################
########################################################################
### An?lise de deviance - avalia??o da qualidade do ajuste.
### Vamos usar este modelo para avaliar a qualidade do ajuste com base na
### deviance residual. Vamos usar, a princ?pio, a aproxima??o com a distribui??o
### qui-quadrado com n-p (496) graus de liberdade.
ajuste2_int$deviance
### Deviance residual (estat?stica do teste da qualidade do ajuste).
qchisq(0.05, df = ajuste2_int$df.residual, lower.tail = FALSE)
### Valor cr?tico.
### Como a deviance excede o valor cr?tico, rejeitar?amos ao n?vel de
### signific?ncia de 5%, a hip?tese nula de que o modelo ajustado est?
### corretamente especificado. Vamos ver o valor-p do teste:
pchisq(ajuste2_int$deviance, df = ajuste2_int$df.residual, lower.tail = FALSE)
### p = 0.018, refor?ando a evid?ncia de que o modelo n?o ? adequado.
### No entanto, ? bem conhecido que a aproxima??o da deviance pela distribui??o
### qui-quadrado (n-p), sob a hip?tese nula de que o modelo ? correto, nem
### sempre ? apropriada. Ent?o, como alternativa, vamos obter a distribui??o
### sob H0 via simula??o.
### Para isso, precisamos simular dados sob a hip?tese nula, de que o modelo
### ? correto. Como fazemos isso?
### Considere a primeira linha da base:
dados[1,]
### Para esse indiv?duo, o valor ajustado pelo modelo ? dado por:
fitted(ajuste2_int)[1]
### Podemos simular uma resposta para essa observa??o, a partir do modelo,
### da seguinte forma:
rpois(1, fitted(ajuste2_int)[1])
### pronto. este valor foi simulado do modelo. Da mesma forma podemos simular
### uma observa??o para cada linha da base:
dados$y <- rpois(500, fitted(ajuste2_int))
dados$y
### Agora, usamos esse vetor de respostas em substitui??o ao vetor original
### no ajuste do modelo.
ajuste2_intSim <- glm(y~ idade * usop, family = poisson, data = dados)
deviance(ajuste2_intSim)
### Esta ? uma deviance simulada sob H0. Para construir a distribui??o
### emp?rica sob H0, temos que repetir a simula??o um grande n?mero de
### vezes (digamos 1000).
vet_deviance <- numeric() ### Vetor que vai armazenar as deviances.
for(i in 1:1000){
dados$y <- rpois(500, fitted(ajuste2_int))
ajuste2_intSim <- glm(y~ idade * usop, family = poisson, data = dados)
vet_deviance[i] <- deviance(ajuste2_intSim)
}
hist(vet_deviance)
abline(v = ajuste2_int$deviance, col = 'red')
### Fica bem evidente que o valor calculado da deviance n?o ? at?pico ou
### extremo em rela??o aos valores simulados sob H0, o que ? um indicativo
### de que o modelo se ajusta bem aos dados. Vamos calcular o p-valor
### com base na distribui??o emp?rica, pela propor??o de valores simulados
### que excedem o valor original da deviance.
mean(vet_deviance > deviance(ajuste2_int))
### Ou seja, n?o temos qualquer evid?ncia de desajuste do modelo.
########################################################################
########################################################################
########################################################################
### Diagn?stico do ajuste.
x11(width = 10, height = 10)
par(mfrow=c(2,2), cex = 1.25, las = 1, mar = c(4,4,2,2))
plot(ajuste2)
### Os res?duos utlizados ao plotar um objeto da classe glm s?o os res?duos
### componentes da deviance. Nem sempre esses res?duos t?m boa aproxima??o
### com a distribui??o normal se o modelo ajustado estiver correto. Isso
### ocorre, particularmente, para dados bin?rios ou de contagens. Esse
### fato ser? verificado atrav?s de um novo estudo por simula??o, apresentado
### ao final dos scripts. Voltando ? an?lise dos dados,
### ? poss?vel notar comportamento mais aceit?vel (vari?ncia mais homog?nea,
### melhor aproxima??o com a distribui??o Normal) em rela??o ao que foi
### verificado para o modelo linear.
### para uma melhor aprecia??o do comportamento dos res?duos, vamos proceder
### com a an?lise dos res?duos quant?licos aleatorizados e a obten??o do
### gr?fico meio normal com envelopes simulados.
residuos <- qres.pois(ajuste2)
ajustados <- predict(ajuste2)
x11(width = 12, height = 8)
par(las = 1, mar = c(4,4,2,2), mfrow = c(1,2), cex = 1.4)
plot(residuos ~ ajustados, col = 'blue', xlab = 'Valores ajustados', ylab = 'Res?duos')
lines(lowess(residuos ~ ajustados), col = 'red', lwd = 2)
qqnorm(residuos, col = 'blue', main = '')
qqline(residuos, lty = 2)
### A curvatura da fun??o suave, presente no gr?fico ? esquerda, ? resultante
### da pequena quantidade de pontos nos extremos dos valores ajustados.
### De qualquer forma, fica evidente que os res?duos tem dispers?o aproxim.
### constante e boa aproxima??o com a distribui??o Normal.
shapiro.test(residuos) ### teste de Shapiro-Wilks para normalidade.
### A hip?tese nula de normalidade n?o ? rejeitada.
### Como alternativa, vamos usar os gr?ficos meio normais com envelopes
### simulados.
x11()
par(las = 1, mar = c(5,4.5,2,2), cex = 1.4)
hnp(ajuste2)
### O gr?fico indica que o modelo se ajusta bem aos dados.
### Gr?ficos de res?duos parciais
### Usando recursos de diagn?stico do pacote car:
x11(width = 15, height = 15)
crPlots(ajuste2, cex = 2, pch = 20)
### Gr?ficos de res?duos parciais
residualPlots(ajuste, cex = 2, pch = 20)
### Gr?fico de res?duos versus vari?veis ajustadas no modelo.
########################################################################
########################################################################
########################################################################
### Diagn?stico de outliers e pontos influentes.
### Vamos fazer uma an?lise de influ?ncia usando recursos do pacote car.
influenceIndexPlot(ajuste2, vars = c('Studentized','Cook','Hat'), id.n = 3)
### O gr?fico dos res?duos studentizados n?o indica observa??es com res?duos extremos.
### O gr?fico da dist?ncia de Cook tem dois pontos mais discrepantes: 15 e 385.
### O gr?fico dos valores de h aponta a observa??o 295 como poss?vel ponto de alavanca.
### Vamos avaliar os dados destacados na an?lise.
dados[15,]
dados[295,]
dados[385,]
### Vamos ver o summary dos dados e do ajuste para entender melhor o por
### que desse dados serem destacados.
summary(dados)
summary(ajuste2)
# O indiv?duo 15 gerou nove sinistros, sendo o segurado com maior n?mero
# de sinistros;
# O indiv?duo 385 tem 47 anos e usa o carro na cidade, mas registrou um
# n?mero elevado de sinistros (cinco).
# O indiv?duo 295 ? at?pico, tem 16 anos de idade e 16 de estudo!!! Deve
# ser erro de registro.
### Vamos tirar da base as observa??es 15, 295 e 385 e reajustar o modelo.
ajuste3 <- update(ajuste2, subset= -c(15,295,385))
compareCoefs(ajuste2, ajuste3)
multiplot(ajuste2, ajuste3) + theme_bw(base_size = 20)
### Compara??o de estimativas e erros padr?es produzidos pelos dois modelos.
### Os resultados (e, consequentemente, as infer?ncias) n?o mudam de forma
### substancial ao remover as tr?s informa??es da base.
########################################################################
########################################################################
########################################################################
### Simula??o - distribui??o dos res?duos componentes da deviance.
### Vamos considerar um glm com resposta binomial, liga??o logito. Seguem
### os dados.
x <- c(5.4, 5.5, 6.2, 4.5, 6.5, 6.8, 5.2, 4.9, 5.9, 4.6,
6.2, 3.3, 6.4, 5.3, 5.1, 5.6, 3.8, 5.3, 5.1, 5.8,
4.5, 4.2, 5.8, 3.6, 4.2, 6.0, 7.1, 4.9, 4.8, 4.0,
6.3, 6.9, 5.6, 6.0, 4.1, 3.9, 6.2, 3.5, 5.1, 2.5,
5.2, 5.3, 3.1, 3.6, 5.8, 5.4, 5.1, 3.8, 6.1, 4.9)
y <- c(1, 1, 0, 0, 0, 0, 0, 0, 1, 0,
0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 1, 1, 1, 0, 0, 0,
1, 1, 0, 1, 0, 0, 0, 0, 0, 0,
0, 1, 0, 1, 0, 1, 0, 0, 1, 0)
plot(jitter(x), jitter(y), pch = 20)
ajuste <- glm(y ~x, family = binomial)
qqnorm(resid(ajuste), pch = 20, cex = 1.5)
qqline(resid(ajuste))
### A distribui??o dos res?duos claramente n?o tem boa ader?ncia ? distribui??o
### normal. Mas ser? que isso implica que o modelo n?o se ajusta bem aos dados?
### Para investigar a adequa??o do ajuste, com base nesse gr?fico de res?duos,
### vamos analisar a distribui??o dos res?duos, nesta aplica??o, no cen?rio
### em que o modelo est? corretamente especificado. Como? Usando simula??o, oras!
novoy <- simulate(ajuste)$sim_1
novoy
### O vetor novoy armazena um vetor de respostas simulado a partir do modelo.
### O m?todo de simula??o ? id?ntico ao que usamos anteriormente, para analisar
### a distribui??o da deviance, usando a fun??o predict. Vamos substituir o
### vetor resposta original por este simulado e analisar os res?duos.
ajustesim <- glm(novoy ~x, family = binomial)
qqnorm(resid(ajustesim), pch = 20, col = 'grey70', cex = 1, ylim = c(-3,3))
qqline(resid(ajustesim))
### Os res?duos, novamente, n?o apresentam distribui??o normal. S? que neste
### caso n?o temos d?vidas que o modelo tenha sido corretamente especificado,
### uma vez que os dados foram simulados a partir do modelo. Agora, vamos repetir
### a simula??o um grande n?mero de vezes (no caso 100) e plotar, num ?nico
### gr?fico, os res?duos produzidos por cada ajuste.
for(i in 1:100){
novoy <- simulate(ajuste)$sim_1
ajustesim <- glm(novoy ~x, family = binomial)
q1 <- qqnorm(resid(ajustesim), pch = 20, col = 'red', plot.it = FALSE, cex = 0.05)
points(q1$x, q1$y, col = 'grey70')
}
### Sobre esta base de res?duos simulados, vamos plotar os res?duos originais,
### produzidos pelos modelo ajustado que est? sob investiga??o.
qorig <- qqnorm(resid(ajuste), pch = 20, cex = 1.5, plot.it = FALSE)
points(qorig$x, qorig$y, pch = 20, cex = 1.5)
### Observe que os res?duos produzidos pelo modelo s?o absolutamente compat?veis
### com os res?duos simulados. Assim, temos forte evid?ncia de que o modelo
### est? corretamente especificado, se ajustando bem aos dados.
########################################################################
########################################################################
########################################################################
### Ilustra??o - res?duo quant?lico aleatorizado.
### Vamos simular dados de um GLM com resposta Gamma e fun??o de liga??o
### logar?tmica. Vamos usar a implementa??o da distribui??o Gamma dispon?vel
### no pacote gamlss (bater ?GA, no pacote gamlss).
require(gamlss)
x <- runif(1000, 0, 2)
y <- rGA(1000, mu = exp(3-x), sigma = 0.5)
plot(x,y)
ajuste <- glm(y~x, family = Gamma(link = 'log'))
### Passo 1: Vamos avaliar a fun??o distribui??o acumulada da Gamma em
### cada par y_i, mu_i.
fgamma <- pGA(y[order(x)], mu = fitted(ajuste)[order(x)], sigma = 0.5)
hist(fgamma)
### Como era de se esperar, a vari?vel resultante tem distribui??o uniforme.
### Agora, aplicamos a inversa da fda Normal (fun??o quantil) aos valores
### de fgamma.
hist(qnorm(fgamma))
### Res?duos com distribui??o normal.
