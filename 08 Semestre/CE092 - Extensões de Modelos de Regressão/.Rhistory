lm2 <- logLik(m2)
# 03 - Modelo gaussiano para log(y1) com preditor linear em x e função de ligação canônica.
m3 <- lm(log(y1) ~ x, data = tb1)
lm3 <- logLik(m3) - sum(log(tb1$y1))
# 04 - Modelo gaussiano para sqrt^y1 com preditor linear em x e função de ligação canônica.
m4 <- lm(sqrt(y1) ~ x, data = tb1)
# lm4 <- logLik(m4) - 0.5 * sum(log(tb1$y1))
lm4 <- logLik(m4) - sum(log(2 * sqrt(tb1$y1)))
l <- MASS::boxcox(tb1$y1 ~ tb1$x)
l <- l$x[which.max(l$y)]
abline(v = 0.5)
m5 <- lm((y1^l - 1)/l ~ x, data = tb1)
lm5 <- logLik(m5) - (1/l - 1) * sum(log(tb1$y1^l))
# 06 - Modelo gama para y1 com preditor linear em x e função de ligação canônica.
m6 <- glm(y1 ~ x, data = tb1, family = Gamma)
lm6 <- logLik(m6)
# 07 - Modelo gaussiano inverso para y1 com preditor linear em x e função de ligação canônica.
m7 <- glm(y1 ~ x, data = tb1, family = inverse.gaussian)
lm7 <- logLik(m7)
# 08 - Modelo gaussiano para y1 com preditor linear em x e função de ligação logarítmica.
m8 <- glm(y1 ~ x, data = tb1, family = gaussian(link=log))
lm8 <- logLik(m8)
veros <- c(lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8)
modelo <- c("M1", "M2", "M3", "M4", "M5", "M6", "M7", "M8")
df.vero <- data.frame(modelo, veros)
df.vero
#d. O uso da função de ligação logarítmica no modelo 8 deu log-verossmilhaça inferior ao modelo 1 que usou função de ligação identitidade.
lm8<lm1
veros <- c(lm1, lm2, lm6, lm7, lm8)
modelo <- c("M1", "M2", "M6", "M7", "M8")
df.vero <- data.frame(modelo, veros)
df.vero
max(df.vero$veros)
#f. O modelo 2 com termo quadrático no preditor produziu log-verossimilhança inferior ao modelo 1.
lm2<lm1
#g. No intervalo x∈[0.5,1.5], o valor predito, y^, pelo modelo 1 é superior ao valor predito pelo modelo 2.
all(predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05))) > predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05))))
pred1 <- predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05)))
pred2 <- predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05)))
sum(pred1) > sum(pred2)
#g. No intervalo x∈[0.5,1.5], o valor predito, y^, pelo modelo 1 é superior ao valor predito pelo modelo 2.
all(predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05))) > predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05))))
plot(y1 ~ x, data = tb1)
lines(seq(0.5, 1.5, 0.05), pred1)
lines(seq(0.5, 1.5, 0.05), pred2)
lines(seq(0.5, 1.5, 0.05), pred2), col = "red")
lines(seq(0.5, 1.5, 0.05), pred2), col = "red")
plot(y1 ~ x, data = tb1)
lines(seq(0.5, 1.5, 0.05), pred1, col = 1)
lines(seq(0.5, 1.5, 0.05), pred2), col = "red")
lines(seq(0.5, 1.5, 0.05), pred2, col = "red")
#h. Na origem (x=0), o modelo 3 tem valor predito inferior ao do modelo 4.
predict(m3, newdata = data.frame(x = 0)) < predict(m4, newdata = data.frame(x = 0))
predict(m4, newdata = data.frame(x = 0))
predict(m3, newdata = data.frame(x = 0))
ym1 <- predict(m1, newdata = data.frame(x = seq(0.75, 1.5, 0.05)))                      # lm(y ~ x)
ym2 <- predict(m2, newdata = data.frame(x = seq(0.75, 1.5, 0.05)))                      # lm(y ~ x + x²)
ym3 <- predict(m3, newdata = data.frame(x = seq(0.75, 1.5, 0.05)))                      # lm(log(y) ~ x)
ym4 <- predict(m4, newdata = data.frame(x = seq(0.75, 1.5, 0.05)))                      # lm(sqrt(y) ~ x)
ym5 <- predict(m5, newdata = data.frame(x = seq(0.75, 1.5, 0.05)))                      # lm(BC(y) ~ x)
ym6 <- predict(m6, newdata = data.frame(x = seq(0.75, 1.5, 0.05)), type = "response")   # glm(y ~ Gamma(x))
ym7 <- predict(m7, newdata = data.frame(x = seq(0.75, 1.5, 0.05)), type = "response")   # glm(y ~ NormInv(x))
ym8 <- predict(m8, newdata = data.frame(x = seq(0.75, 1.5, 0.05)), type = "response")   # glm(y ~ LogNorm(x))
plot(y1 ~ x, data = tb1)
lines(seq(0.75, 1.5, 0.05), ym1)
plot(y1 ~ x, data = tb1)
lines(seq(0.75, 1.5, 0.05), ym1)
lines(seq(0.75, 1.5, 0.05), ym6, col = "red")
lines(seq(0.75, 1.5, 0.05), ym6, col = "blue")
plot(y1 ~ x, data = tb1)
lines(seq(0.75, 1.5, 0.05), ym1)
lines(seq(0.75, 1.5, 0.05), ym6, col = "red")
lines(seq(0.75, 1.5, 0.05), ym7, col = "blue")
abline(v = c(0.75, 1.5), lty = 2, col = "green")
sum(m7 - m1)^2 < sum(m6 - m1)^2
sum(ym7 - ym1)^2 < sum(ym6 - ym1)^2
#j. A transformação da resposta no modelo 3 é mais apropriada que a transformação feita no modelo 4.
lm3>lm4
AIC(lm3)<AIC(lm4)
#k. A log-verossimilhança do modelo 3, corrigida para a escala natural da variável resposta, foi -54.70.
lm3
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), ym1)
y1
tb1$y1
#l. Considerando apenas os modelos que não fizeram transformação da variável resposta, os modelos com valores preditos mais
#próximos um do outro foram 2 e 8.
# ********* 1,2,6,7,8 *********
plot(y1 ~ x, data = tb1)
seq(0, 2, 0.05)
lines(seq(0, 2, 0.05), ym1)
rm(list=ls())
##
#Considere os dados disponíveis no objeto tb1 criado com o código R do bloco a seguir.
tb1 <- data.frame(x = seq(0, 2, by = 0.1),
y1 = c(5.5, 7.2, 10.4, 7.4, 7.2, 9.1, 15.9, 12.7,
11.3, 14.4, 14.8, 17.1, 31.4, 17.5, 27.6, 19.6,
27.1, 21, 33.8, 30.2, 45.1),
y2 = c(0.8, 1.5, 2.6, 1.5, 1.4, 2.1, 3.9, 3.3, 3, 3.9,
4.2, 4.8, 6.9, 5.5, 7.3, 6.7, 8.2, 8.1, 10.2,
10.7, 12.8))
#Digrama de dispersão.
xyplot(y1 + y2 ~ x, data = tb1, outer = TRUE, scales = "free")
m1 <- lm(y1 ~ x, data = tb1)
lm1 <- logLik(m1)
# 02 - Modelo gaussiano para y1 com preditor quadrático em x e função de ligação canônica.
m2 <- lm(y1 ~ x + I(x^2), data = tb1)
lm2 <- logLik(m2)
# 03 - Modelo gaussiano para log(y1) com preditor linear em x e função de ligação canônica.
m3 <- lm(log(y1) ~ x, data = tb1)
lm3 <- logLik(m3) - sum(log(tb1$y1))
# 04 - Modelo gaussiano para sqrt^y1 com preditor linear em x e função de ligação canônica.
m4 <- lm(sqrt(y1) ~ x, data = tb1)
# lm4 <- logLik(m4) - 0.5 * sum(log(tb1$y1))
lm4 <- logLik(m4) - sum(log(2 * sqrt(tb1$y1)))
# 05 - Modelo gaussiano para BoxCox(y1)=(y1^L-1)/L com preditor linear em x e função de ligação canônica. O valor de L é o que otimiza
# a log-verossimilhança perfilhada.
l <- MASS::boxcox(tb1$y1 ~ tb1$x)
l <- l$x[which.max(l$y)]
abline(v = 0.5)
m5 <- lm((y1^l - 1)/l ~ x, data = tb1)
lm5 <- logLik(m5) - (1/l - 1) * sum(log(tb1$y1^l))
# 06 - Modelo gama para y1 com preditor linear em x e função de ligação canônica.
m6 <- glm(y1 ~ x, data = tb1, family = Gamma)
lm6 <- logLik(m6)
# 07 - Modelo gaussiano inverso para y1 com preditor linear em x e função de ligação canônica.
m7 <- glm(y1 ~ x, data = tb1, family = inverse.gaussian)
lm7 <- logLik(m7)
# 08 - Modelo gaussiano para y1 com preditor linear em x e função de ligação logarítmica.
m8 <- glm(y1 ~ x, data = tb1, family = gaussian(link=log))
lm8 <- logLik(m8)
veros <- c(lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8)
modelo <- c("M1", "M2", "M3", "M4", "M5", "M6", "M7", "M8")
df.vero <- data.frame(modelo, veros)
df.vero
#a. A log-verossimilhança do modelo 3 foi superior a do 1.
lm3>lm1
#b. A log-verossimilhança do modelo 4 foi superior a do 1.
lm4>lm1
AIC(m6) < AIC(m7)
lm6 > lm7
#d. O uso da função de ligação logarítmica no modelo 8 deu log-verossmilhaça inferior ao modelo 1 que usou função de ligação identitidade.
lm8<lm1
#e. Dentre os modelos que não transformaram a variável resposta, a maior log-verossmilhança é a do modelo 8.
# ********* 1,2,6,7,8 *********
veros <- c(lm1, lm2, lm6, lm7, lm8)
modelo <- c("M1", "M2", "M6", "M7", "M8")
df.vero <- data.frame(modelo, veros)
max(df.vero$veros)
df.vero
max(df.vero$veros)
#f. O modelo 2 com termo quadrático no preditor produziu log-verossimilhança inferior ao modelo 1.
lm2<lm1
#g. No intervalo x∈[0.5,1.5], o valor predito, y^, pelo modelo 1 é superior ao valor predito pelo modelo 2.
all(predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05))) > predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05))))
# avaliando a soma
sum(pred1) > sum(pred2)
pred1 <- predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05)))
pred2 <- predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05)))
sum(pred1) > sum(pred2)
#g. No intervalo x∈[0.5,1.5], o valor predito, y^, pelo modelo 1 é superior ao valor predito pelo modelo 2.
all(predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05))) > predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05))))
# avaliando M1 - M2
df.1x2 <-c(predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05))) - predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05))))
df.1x2
plot(y1 ~ x, data = tb1)
lines(seq(0.5, 1.5, 0.05), pred1, col = 1)
lines(seq(0.5, 1.5, 0.05), pred2, col = "red")
ym1 <- predict(m1, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(y ~ x)
ym2 <- predict(m2, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(y ~ x + x²)
ym3 <- predict(m3, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(log(y) ~ x)
ym4 <- predict(m4, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(sqrt(y) ~ x)
ym5 <- predict(m5, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(BC(y) ~ x)
ym6 <- predict(m6, newdata = data.frame(x = seq(0, 2, 0.05)), type = "response")   # glm(y ~ Gamma(x))
ym7 <- predict(m7, newdata = data.frame(x = seq(0, 2, 0.05)), type = "response")   # glm(y ~ NormInv(x))
ym8 <- predict(m8, newdata = data.frame(x = seq(0, 2, 0.05)), type = "response")   # glm(y ~ LogNorm(x))
# avaliando distancia quadratica
sum(ym7 - ym1)^2 < sum(ym6 - ym1)^2
# avaliando graficamente
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), ym1)
lines(seq(0, 2, 0.05), ym6, col = "red")
lines(seq(0, 2, 0.05), ym7, col = "blue")
abline(v = c(0.75, 1.5), lty = 2, col = "green")
#j. A transformação da resposta no modelo 3 é mais apropriada que a transformação feita no modelo 4.
lm3>lm4
AIC(lm3)<AIC(lm4)
#k. A log-verossimilhança do modelo 3, corrigida para a escala natural da variável resposta, foi -54.70.
lm3
#l. Considerando apenas os modelos que não fizeram transformação da variável resposta, os modelos com valores preditos mais
#próximos um do outro foram 2 e 8.
# ********* 1,2,6,7,8 *********
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), ym1)
lines(seq(0, 2, 0.05), ym2, col = "red")
lines(seq(0, 2, 0.05), ym6, col = "blue")
lines(seq(0, 2, 0.05), ym7, col = "purple")
lines(seq(0, 2, 0.05), ym8, col = "yellow")
abline(v = c(0.75, 1.5), lty = 2, col = "green")
rm(list=ls())
##
#Considere os dados disponíveis no objeto tb1 criado com o código R do bloco a seguir.
tb1 <- data.frame(x = seq(0, 2, by = 0.1),
y1 = c(5.5, 7.2, 10.4, 7.4, 7.2, 9.1, 15.9, 12.7,
11.3, 14.4, 14.8, 17.1, 31.4, 17.5, 27.6, 19.6,
27.1, 21, 33.8, 30.2, 45.1),
y2 = c(0.8, 1.5, 2.6, 1.5, 1.4, 2.1, 3.9, 3.3, 3, 3.9,
4.2, 4.8, 6.9, 5.5, 7.3, 6.7, 8.2, 8.1, 10.2,
10.7, 12.8))
library(lattice)
library(latticeExtra)
xyplot(y1 + y2 ~ x, data = tb1, outer = TRUE, scales = "free")
# Essa tabela de dados contém os valores de duas variáveis respostas, y1 e y2, como função de uma variável quantitativa x. Apesar de estarem na
# mesma tabela, y1 e y2 não são medidas observadas juntas mas sim de experimentos diferentes mas coincidentemente observadas sob os mesmos
# valores da variável independente x.
# 01 - Modelo gaussiano para y1 com preditor linear em x e função de ligação canônica.
m1 <- lm(y1 ~ x, data = tb1)
lm1 <- logLik(m1)
grid1 <- predict(m1, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(y ~ x)
# 02 - Modelo gaussiano para y1 com preditor quadrático em x e função de ligação canônica.
m2 <- lm(y1 ~ x + I(x^2), data = tb1)
lm2 <- logLik(m2)
grid2 <- predict(m2, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(y ~ x + x²)
# 03 - Modelo gaussiano para log(y1) com preditor linear em x e função de ligação canônica.
m3 <- lm(log(y1) ~ x, data = tb1)
lm3 <- logLik(m3) - sum(log(tb1$y1))
grid3 <- predict(m3, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(log(y) ~ x)
# 04 - Modelo gaussiano para sqrt^y1 com preditor linear em x e função de ligação canônica.
m4 <- lm(sqrt(y1) ~ x, data = tb1)
# lm4 <- logLik(m4) - 0.5 * sum(log(tb1$y1))
lm4 <- logLik(m4) - sum(log(2 * sqrt(tb1$y1)))
grid4 <- predict(m4, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(sqrt(y) ~ x)
# 05 - Modelo gaussiano para BoxCox(y1)=(y1^L-1)/L com preditor linear em x e função de ligação canônica. O valor de L é o que otimiza
# a log-verossimilhança perfilhada.
l <- MASS::boxcox(tb1$y1 ~ tb1$x)
l <- l$x[which.max(l$y)]
abline(v = 0.5)
m5 <- lm((y1^l - 1)/l ~ x, data = tb1)
lm5 <- logLik(m5) - (1/l - 1) * sum(log(tb1$y1^l))
grid5 <- predict(m5, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(BC(y) ~ x)
# 06 - Modelo gama para y1 com preditor linear em x e função de ligação canônica.
m6 <- glm(y1 ~ x, data = tb1, family = Gamma)
lm6 <- logLik(m6)
grid6 <- predict(m6, newdata = data.frame(x = seq(0, 2, 0.05)), type = "response")   # glm(y ~ Gamma(x))
# 07 - Modelo gaussiano inverso para y1 com preditor linear em x e função de ligação canônica.
m7 <- glm(y1 ~ x, data = tb1, family = inverse.gaussian)
lm7 <- logLik(m7)
grid7 <- predict(m7, newdata = data.frame(x = seq(0, 2, 0.05)), type = "response")   # glm(y ~ NormInv(x))
# 08 - Modelo gaussiano para y1 com preditor linear em x e função de ligação logarítmica.
m8 <- glm(y1 ~ x, data = tb1, family = gaussian(link=log))
lm8 <- logLik(m8)
grid8 <- predict(m8, newdata = data.frame(x = seq(0, 2, 0.05)), type = "response")   # glm(y ~ LogNorm(x))
veros <- c(lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8)
modelo <- c("M1", "M2", "M3", "M4", "M5", "M6", "M7", "M8")
df.vero <- data.frame(modelo, veros)
df.vero
#a. A log-verossimilhança do modelo 3 foi superior a do 1.
lm3>lm1
#b. A log-verossimilhança do modelo 4 foi superior a do 1.
lm4>lm1
AIC(m6) < AIC(m7)
lm6 > lm7
#a. A log-verossimilhança do modelo 3 foi superior a do 1.
lm3>lm1
#b. A log-verossimilhança do modelo 4 foi superior a do 1.
lm4>lm1
#c. A distribuição considerada no modelo 6 é mais apropriada para os dados que a do modelo 7.
AIC(m6) < AIC(m7)
lm6 > lm7
#d. O uso da função de ligação logarítmica no modelo 8 deu log-verossmilhaça inferior ao modelo 1 que usou função de ligação identitidade.
lm8<lm1
max(df.vero$veros)
veros <- c(lm1, lm2, lm6, lm7, lm8)
modelo <- c("M1", "M2", "M6", "M7", "M8")
df.vero <- data.frame(modelo, veros)
df.vero
max(df.vero$veros)
#f. O modelo 2 com termo quadrático no preditor produziu log-verossimilhança inferior ao modelo 1.
lm2<lm1
#g. No intervalo x∈[0.5,1.5], o valor predito, y^, pelo modelo 1 é superior ao valor predito pelo modelo 2.
all(predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05))) > predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05))))
# avaliando a soma
sum(grid1) > sum(grid2)
# avaliando M1 - M2
df.1x2 <-c(predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05))) - predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05))))
df.1x2
# avaliando graficamente
plot(y1 ~ x, data = tb1)
lines(seq(0.5, 1.5, 0.05), grid1, col = 1)
#g. No intervalo x∈[0.5,1.5], o valor predito, y^, pelo modelo 1 é superior ao valor predito pelo modelo 2.
all(predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05))) > predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05))))
# avaliando a soma
sum(grid1) > sum(grid2)
# avaliando M1 - M2
df.1x2 <-c(predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05))) - predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05))))
df.1x2
# avaliando graficamente
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), grid1, col = 1)
lines(seq(0, 2, 0.05), grid2, col = "red")
abline(v = c(0.5, 1.5), lty = 2, col = "green")
#h. Na origem (x=0), o modelo 3 tem valor predito inferior ao do modelo 4.
predict(m3, newdata = data.frame(x = 0)) < predict(m4, newdata = data.frame(x = 0))
#h. Na origem (x=0), o modelo 3 tem valor predito inferior ao do modelo 4.
predict(m3, newdata = data.frame(x = 0)) < predict(m4, newdata = data.frame(x = 0))
grid3[0]<grid4[0]
grid3[0] < grid4[0]
grid3[0]
#h. Na origem (x=0), o modelo 3 tem valor predito inferior ao do modelo 4.
predict(m3, newdata = data.frame(x = 0)) < predict(m4, newdata = data.frame(x = 0))
predict(m3, newdata = data.frame(x = 0))
predict(m4, newdata = data.frame(x = 0))
#i. No intervalo x∈[0.75,1.5], os valores preditos pelo modelo 7 estão mais próximas do modelo 1 que o modelo 6 do modelo 1.
# avaliando distancia quadratica
sum(grid7 - grid1)^2 < sum(grid - grid1)^2
#i. No intervalo x∈[0.75,1.5], os valores preditos pelo modelo 7 estão mais próximas do modelo 1 que o modelo 6 do modelo 1.
# avaliando distancia quadratica
sum(grid7 - grid1)^2 < sum(grid6 - grid1)^2
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), grid1)
lines(seq(0, 2, 0.05), grid6, col = "red")
lines(seq(0, 2, 0.05), grid7, col = "blue")
abline(v = c(0.75, 1.5), lty = 2, col = "green")
lm3>lm4
AIC(lm3)<AIC(lm4)
#k. A log-verossimilhança do modelo 3, corrigida para a escala natural da variável resposta, foi -54.70.
lm3
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), grid1)
lines(seq(0, 2, 0.05), grid2, col = "red")
lines(seq(0, 2, 0.05), grid6, col = "blue")
lines(seq(0, 2, 0.05), grid7, col = "purple")
lines(seq(0, 2, 0.05), grid8, col = "yellow")
abline(v = c(0.75, 1.5), lty = 2, col = "green")
#TRUE
rm(list=ls())
##
#Considere os dados disponíveis no objeto tb1 criado com o código R do bloco a seguir.
tb1 <- data.frame(x = seq(0, 2, by = 0.1),
y1 = c(5.5, 7.2, 10.4, 7.4, 7.2, 9.1, 15.9, 12.7,
11.3, 14.4, 14.8, 17.1, 31.4, 17.5, 27.6, 19.6,
27.1, 21, 33.8, 30.2, 45.1),
y2 = c(0.8, 1.5, 2.6, 1.5, 1.4, 2.1, 3.9, 3.3, 3, 3.9,
4.2, 4.8, 6.9, 5.5, 7.3, 6.7, 8.2, 8.1, 10.2,
10.7, 12.8))
library(lattice)
library(latticeExtra)
#Digrama de dispersão.
xyplot(y1 + y2 ~ x, data = tb1, outer = TRUE, scales = "free")
# Essa tabela de dados contém os valores de duas variáveis respostas, y1 e y2, como função de uma variável quantitativa x. Apesar de estarem na
# mesma tabela, y1 e y2 não são medidas observadas juntas mas sim de experimentos diferentes mas coincidentemente observadas sob os mesmos
# valores da variável independente x.
# 01 - Modelo gaussiano para y1 com preditor linear em x e função de ligação canônica.
m1 <- lm(y1 ~ x, data = tb1)
lm1 <- logLik(m1)
grid1 <- predict(m1, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(y ~ x)
# 02 - Modelo gaussiano para y1 com preditor quadrático em x e função de ligação canônica.
m2 <- lm(y1 ~ x + I(x^2), data = tb1)
lm2 <- logLik(m2)
grid2 <- predict(m2, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(y ~ x + x²)
# 03 - Modelo gaussiano para log(y1) com preditor linear em x e função de ligação canônica.
m3 <- lm(log(y1) ~ x, data = tb1)
lm3 <- logLik(m3) - sum(log(tb1$y1))
grid3 <- predict(m3, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(log(y) ~ x)
# 04 - Modelo gaussiano para sqrt^y1 com preditor linear em x e função de ligação canônica.
m4 <- lm(sqrt(y1) ~ x, data = tb1)
# lm4 <- logLik(m4) - 0.5 * sum(log(tb1$y1))
lm4 <- logLik(m4) - sum(log(2 * sqrt(tb1$y1)))
grid4 <- predict(m4, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(sqrt(y) ~ x)
# 05 - Modelo gaussiano para BoxCox(y1)=(y1^L-1)/L com preditor linear em x e função de ligação canônica. O valor de L é o que otimiza
# a log-verossimilhança perfilhada.
l <- MASS::boxcox(tb1$y1 ~ tb1$x)
l <- l$x[which.max(l$y)]
abline(v = 0.5)
m5 <- lm((y1^l - 1)/l ~ x, data = tb1)
lm5 <- logLik(m5) - (1/l - 1) * sum(log(tb1$y1^l))
grid5 <- predict(m5, newdata = data.frame(x = seq(0, 2, 0.05)))                      # lm(BC(y) ~ x)
# 06 - Modelo gama para y1 com preditor linear em x e função de ligação canônica.
m6 <- glm(y1 ~ x, data = tb1, family = Gamma)
lm6 <- logLik(m6)
grid6 <- predict(m6, newdata = data.frame(x = seq(0, 2, 0.05)), type = "response")   # glm(y ~ Gamma(x))
# 07 - Modelo gaussiano inverso para y1 com preditor linear em x e função de ligação canônica.
m7 <- glm(y1 ~ x, data = tb1, family = inverse.gaussian)
lm7 <- logLik(m7)
grid7 <- predict(m7, newdata = data.frame(x = seq(0, 2, 0.05)), type = "response")   # glm(y ~ NormInv(x))
# 08 - Modelo gaussiano para y1 com preditor linear em x e função de ligação logarítmica.
m8 <- glm(y1 ~ x, data = tb1, family = gaussian(link=log))
lm8 <- logLik(m8)
grid8 <- predict(m8, newdata = data.frame(x = seq(0, 2, 0.05)), type = "response")   # glm(y ~ LogNorm(x))
veros <- c(lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8)
modelo <- c("M1", "M2", "M3", "M4", "M5", "M6", "M7", "M8")
df.vero <- data.frame(modelo, veros)
df.vero
###################################################################################################################
#Obtenha os valores preditos na escala da variável resposta para a sequência de valores de x em 0,0.05,0.10,.,2.
#a. A log-verossimilhança do modelo 3 foi superior a do 1.
lm3>lm1
#true
#b. A log-verossimilhança do modelo 4 foi superior a do 1.
lm4>lm1
#true
AIC(m6) < AIC(m7)
lm6 > lm7
#true
#d. O uso da função de ligação logarítmica no modelo 8 deu log-verossmilhaça inferior ao modelo 1 que usou função de ligação identitidade.
lm8<lm1
#false
#e. Dentre os modelos que não transformaram a variável resposta, a maior log-verossmilhança é a do modelo 8.
# ********* 1,2,6,7,8 *********
veros <- c(lm1, lm2, lm6, lm7, lm8)
modelo <- c("M1", "M2", "M6", "M7", "M8")
df.vero <- data.frame(modelo, veros)
df.vero
max(df.vero$veros)
#false, a maior é M6
#f. O modelo 2 com termo quadrático no preditor produziu log-verossimilhança inferior ao modelo 1.
lm2<lm1
#false
all(predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05))) > predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05))))
# avaliando a soma
sum(grid1) > sum(grid2)
# avaliando M1 - M2
df.1x2 <-c(predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05))) - predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05))))
df.1x2
# avaliando graficamente
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), grid1, col = 1)
lines(seq(0, 2, 0.05), grid2, col = "red")
abline(v = c(0.5, 1.5), lty = 2, col = "green")
predict(m3, newdata = data.frame(x = 0)) < predict(m4, newdata = data.frame(x = 0))
#true
#i. No intervalo x∈[0.75,1.5], os valores preditos pelo modelo 7 estão mais próximas do modelo 1 que o modelo 6 do modelo 1.
# avaliando distancia quadratica
sum(grid7 - grid1)^2 < sum(grid6 - grid1)^2
# avaliando graficamente
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), grid1)
lines(seq(0, 2, 0.05), grid6, col = "red")
lines(seq(0, 2, 0.05), grid7, col = "blue")
abline(v = c(0.75, 1.5), lty = 2, col = "green")
#j. A transformação da resposta no modelo 3 é mais apropriada que a transformação feita no modelo 4.
lm3>lm4
AIC(lm3)<AIC(lm4)
#TRUE
#k. A log-verossimilhança do modelo 3, corrigida para a escala natural da variável resposta, foi -54.70.
lm3
#TRUE
#l. Considerando apenas os modelos que não fizeram transformação da variável resposta, os modelos com valores preditos mais
#próximos um do outro foram 2 e 8.
# ********* 1,2,6,7,8 *********
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), grid1)
lines(seq(0, 2, 0.05), grid2, col = "red")
lines(seq(0, 2, 0.05), grid6, col = "blue")
lines(seq(0, 2, 0.05), grid7, col = "purple")
lines(seq(0, 2, 0.05), grid8, col = "yellow")
abline(v = c(0.75, 1.5), lty = 2, col = "green")
#TRUE
df.vero
#a. A log-verossimilhança do modelo 3 foi superior a do 1.
lm3>lm1
#b. A log-verossimilhança do modelo 4 foi superior a do 1.
lm4>lm1
#i. No intervalo x∈[0.75,1.5], os valores preditos pelo modelo 7 estão mais próximas do modelo 1 que o modelo 6 do modelo 1.
# avaliando distancia quadratica
sum(grid7 - grid1)^2 < sum(grid6 - grid1)^2
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), grid1)
lines(seq(0, 2, 0.05), grid6, col = "red")
lines(seq(0, 2, 0.05), grid7, col = "blue")
abline(v = c(0.75, 1.5), lty = 2, col = "green")
#g. No intervalo x∈[0.5,1.5], o valor predito, y^, pelo modelo 1 é superior ao valor predito pelo modelo 2.
all(predict(m1, newdata = data.frame(x = seq(0.5, 1.5, 0.05))) > predict(m2, newdata = data.frame(x = seq(0.5, 1.5, 0.05))))
# avaliando a soma
sum(grid1) > sum(grid2)
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), grid1, col = 1)
lines(seq(0, 2, 0.05), grid2, col = "red")
abline(v = c(0.5, 1.5), lty = 2, col = "green")
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), grid1)
lines(seq(0, 2, 0.05), grid6, col = "red")
lines(seq(0, 2, 0.05), grid7, col = "blue")
abline(v = c(0.75, 1.5), lty = 2, col = "green")
######h. Na origem (x=0), o modelo 3 tem valor predito inferior ao do modelo 4.
predict(m3, newdata = data.frame(x = 0)) < predict(m4, newdata = data.frame(x = 0))
plot(y1 ~ x, data = tb1)
lines(seq(0, 2, 0.05), grid3)
lines(seq(0, 2, 0.05), grid4, col = "red")
abline(v = c(0, 1.5), lty = 2, col = "green")
x03 <- predict(m3, newdata = data.frame(x = 0))
x04 <- predict(m4, newdata = data.frame(x = 0))
x03
x04
grid3
grid4
seq(0, 2, 0.05)
##
ndf <- data.frame(seq(0, 2, 0.05), grid3, grid4)
ndf
#j. A transformação da resposta no modelo 3 é mais apropriada que a transformação feita no modelo 4.
lm3>lm4
AIC(lm3)<AIC(lm4)
veros <- c(lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8)
modelo <- c("M1", "M2", "M3", "M4", "M5", "M6", "M7", "M8")
df.vero <- data.frame(modelo, veros)
df.vero
# 05 - Modelo gaussiano para BoxCox(y1)=(y1^L-1)/L com preditor linear em x e função de ligação canônica. O valor de L é o que otimiza
# a log-verossimilhança perfilhada.
l <- MASS::boxcox(tb1$y1 ~ tb1$x)
l <- l$x[which.max(l$y)]
abline(v = 0.5)
