---
title: "Trabalho Nº3 - Modelos Markovianos"
author: "Rafael Morciani | GRR20160217"
date: "18 de Agosto de 2020"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=4, fig.path='Figs/',                     echo=F,warning=T,message=FALSE,cache=F,comment=NULL)
```

```{r}
##LIMPESA DO HISTORICO DO R
rm(list = ls())
options(digits = 4)

##PACOTES USADOS
library(dplyr)
library(markovchain)
```

### Exercicio 1
Mostrar que se o estado $x$ é recorrente e não se comunica com o estado $y$, então $γ_{x,y}=0$

**Desenvolvimento:**

Seja $S(x,y)$ onde $x$ é um estado recorrente e não se comunica com $y$, ou seja, $\rho_{x,x}=1 \;e \; \rho_{x,y}=0$.

Seja $C_{n}$ uma Cadeia de Markov com espaço de estados $S$ onde $N(y)$ é o número de vezes em que a cadeia permanece no espaço $y$, então:
$$N(y)=\sum_{n=1}^{\infty}I_{y}(C_{n})$$

Também observamos que $N(y)\geq 1$ é o mesmo que $T_{y}<\infty$ logo:
$$P_{x}(N(y)\geq1)=P_{x}(T_{y}<\infty)=\rho_{x,y}$$
Temos que a probabilidade com a qual a cadeia começando em $x$ visitar a primeira vez $y$ no tempo $m$ e visitar novamente no tempo $n$ (onde $m$ e $n$ são inteiros positivos) é:
$$P_{x}(T_{y}=m).P_{y}(T_{y}=n)$$
Logo:
$$P_{x}(N(y)\geq2)=\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}P_{x}(T_{y}=m).P_{y}(T_{y}=n)\\
=\left [ \sum_{m=1}^{\infty}P_{x}(T_{y}=m) \right ].\left [ \sum_{n=1}^{\infty}P_{y}(T_{y}=m)\right ]=\rho_{x,x}\rho_{x,y}=1*0=0$$

\pagebreak

### Exercicio 3
Mostre que se o estado $x$ se comunica com $y$ e $y$ se comunica com $z$, então $x$ se comunica com $z$. 


**Desenvolvimento:**

Se $x$ se comunica com $y$, sabemos que $P_{x}(T_{y}=n)>0$, para algum $n$ finito. 

Se $y$ se comunica com $z$, também sabemos que $P_{y}(T_{z}=m)>0$, para algum $m$ finito.

Então: $P_{x}(T_{z}=m+n)>0$, logo $x$ se comunica com $z$.

\pagebreak

### Exercicio 4
Considere uma Caceia de Markov com espaço de estados ${1,2,⋯,9}$ e matriz de probabilidades de transição 

$$\Gamma = \begin{pmatrix}
0.0 & 0.5 & 0.0 & 0.0 & 0.5 & 0.0 & 0.0 & 0.0 & 0.0 \\
0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\
0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\
1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\
0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 \\
0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 \\
0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 \\
0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0
\end{pmatrix}$$

Esta cadeia é irredutível? Ou seja, prove que o conjunto de estados irredutíveis $F$ satisfaz $F=S$, sendo $S={1,⋯,9}$. Prove também que esta cadeia é recorrente, ou seja, prove que cada estado em $S$ é recorrente. 

**Desenvolvimento:**

```{r}
gamma4 <- matrix(c(0,0.5,0,0,0.5,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,rep(0,8),
                  rep(0,5),1,rep(0,3),rep(0,6),1,0,0,rep(0,7),1,0,rep(0,8),1,1,rep(0,8)), byrow=T, ncol = 9, dimnames=list(1:9))
ProbT4 = new("markovchain", states=as.character(1:9), transitionMatrix=gamma4, name="Γ")
```
Verificando o *summary* da cadeia:

```{r}
summary(ProbT4)
```
Aqui temos que todos os estados se comunicam, logo a matriz é irredutível. Também observamos que os estados são ditos recorrentes.

Do teorema 17: Seja **F** um conjunto finito e fechado de estados irredutíveis. Então cada estado em **F** é recorrente.

Como a matriz é irredutível e todos seus estados são recorrentes, a matriz é dita recorrente.

\pagebreak

### Exercicio 6
**A Fiscalía de Mídia** identificou seis estados associados à televisão: 0 (nunca assiste TV), 1 (assiste apenas notícias), 2 (assiste TV com bastante frequência), 3 (viciado), 4 (em modificação de comportamento), 5 (morte encefálica). As transições de estado para estado podem ser modeladas como uma cadeia de Markov com a seguinte matriz de transição: 

$$\Gamma = \begin{pmatrix}
1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\
0.5 & 0.0 & 0.5 & 0.0 & 0.0 & 0.0 \\
0.1 & 0.0 & 0.5 & 0.3 & 0.0 & 0.1 \\
0.0 & 0.0 & 0.0 & 0.7 & 0.1 & 0.2 \\
1/3 & 0.0 & 0.0 & 1/3 & 1/3 & 0.0 \\
0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0
\end{pmatrix}$$

  
    a) Quais estados são recorrentes e quais transientes.
    b) Começando do estado $1$, qual é a probabilidade de o estado $5$ ser atingido antes do estado $0$, ou seja, qual é a probabilidade de um visualizador de notícias acabar com morte cerebral?


**Desenvolvimento A:**

```{r}
gamma6 <- matrix(c(1,rep(0,5),0.5,0,0.5,rep(0,3),0.1,0,0.5,0.3,0,0.1,rep(0,3),0.7,0.1,0.2,1/3,0,0,1/3,1/3,0,rep(0,5),1), byrow=T, ncol = 6, dimnames=list(0:5))
ProbT6 = new("markovchain", states=as.character(0:5), transitionMatrix=gamma6, name="Γ")
```

```{r}
summary(ProbT6)
```
Pelo *summary* da cadeia temos que os estados recorrentes (e absorventes) são {0} e {5} e os transientes são {1}, {2}, {3,4}.

\pagebreak

**Desenvolvimento B:**

Para encontrarmos as probabilidades assintóticas, podemos utilizar uma potência elevada da matriz de transição:

```{r}
ProbT6^50000
```
Logo, partindo do estado 1, o visualizador terá probabilidade de 0.34 de ter morte cerebral antes de atingir o estado 0.

