---
title: "CADEIAS DE MARKOV - TRABALHO 1"
author: "Yasmin Roberta Fernandes - GRR20137523"
date: "4 de abril de 2019"
output: word_document
---

1.Suponha que a profissão de um homem pode ser classificada como profissional, trabalhador qualificado ou operário não qualificado. Suponha que, dos filhos de homens profissionais, 80 por cento são profissionais, 10 porcento são trabalhadores qualificados e 10 por cento são trabalhadores não qualificados. No caso dos filhos de operários especializados, 60 porcento são hábeis trabalhadores qualificados, 20 porcento são profissionais e 20 porcento são trabalhadores não qualificados. Finalmente, no caso de trabalhadores não qualificados, 50 porcento dos filhos são trabalhadores não qualificados e 25 porcento em cada um são as chances das outras duas categorias. Suponha que cada homem tem pelo menos um filho e que seguindo a profissão de um filho escolhido aleatoriamente de uma determinada família através de várias gerações temos definida uma Cadeia de Markov. Configure a matriz de probabilidades de transição. Encontre a probabilidade de que um neto escolhido aleatoriamente de um trabalhador não qualificado seja um homem profissional.

```{r}
library(markovchain)
estados = c("Profissionais","Qualificados","Não Qualificados")
Prob.T=matrix(c(0.8,0.1,0.1,0.6,0.2,0.2,0.5,0.25,0.25),nrow=3,
              ncol=3,byrow=T, dimnames=list(estados,estados))
ProbT = new("markovchain", states=estados, transitionMatrix=Prob.T,
            name="Classificação de profissão de um homem")
ProbT

```

Probabilidade dos netos a partir da matriz de transição atingirem o estado da classificação:

```{r cars}
ProbT^2
```

Neste caso conforme solicitado no exercício temos que o neto de um neto de um trabalhador não qualificado se tornar
também um trabalhador não qualificado e de aproximadamente 37,5%.

2.Seja {$X_n$ : $n \geq 0$} uma Cadeia de Markov. Mostre que

$$P(X_0=x_0|X_1=x_1,...,X_n=x_n)=P(X_0=x_0|X_1=x_1)$$

Para essa demonstração, vou utilizar outra notação, será provado que:

$$P(A_{3}|A_{1}\cap A_{2})=P(A_{3}|A_{2})$$
$$P(A_{3}|A_{1}\cap A_{2})=\frac{P(A_{1}\cap A_{2} \cap A_{3})}{P(A_{1}\cap A_{2})}$$
$$=\frac{P(A_{1}\cap A_{3}|A_{2})P(A_{1})}{P(A_{1}\cap A_{2})}$$
$$=\frac{P(A_{3}|A_{2})P(A_{1}A_{2})P(A_{2})}{P(A_{1}\cap A_{2})}$$
$$=\frac{P(A_{3}|A_{2})P(A_{1}\cap A_{2})}{P(A_{1}\cap A_{2})}$$
$$=P(A_{3}|A_{2})$$
Ou seja, se dado o estado atual, os estados passados nÃO tem influencia sobre o futuro.


3.  Uma Cadeia de Markov a três estados tem a seguinte matriz de probabilidades de transição:

```{r pressure, echo=FALSE}

PT=matrix(c(0.4,0.5,0.1,0.4,0.5,0.1,0.4,0.5,0.1),nrow=3,
              ncol=3,byrow=T)

```

a)Qual é o valor aproximado de (1001,3) ? Que interpretação você dá a esse resultado?
```{r}
estados3 = c("1","2","3")
Prob.T3=matrix(c(0.4,0.5,0.1,0.4,0.5,0.1,0.4,0.5,0.1),nrow=3,
              ncol=3,byrow=T, dimnames=list(estados3,estados3))
Prob.T3 = new("markovchain", states=estados3, transitionMatrix=Prob.T3,
            name="MATRIZ DE TRANSIÇÃO")
aj <- c(1,0,0)
valoraprox <- aj*(Prob.T3^100)
valoraprox

```
Neste caso observamos que a probabilidade de estarmos no estado 3 após a centésima interação partindo de 1 e de 10%,
definida pela matriz estacionária.
A potência da matriz de probabilidades em transição de um estado para outro é
dada pelo expoente, logo a probabilidade de ir do estado um para o três em 100 transições é dada
por essa matriz.

b) Qual é a probabilidade de que após o terceiro passo a cadeia esteja no estado 3 se o vector de probabilidades
inicial é (1/3, 1/3, 1/3)?
```{r}
pb <- rep(1/3 , 3)
passo3 <- pb*(Prob.T3^3)
passo3
mean(passo3[,3])

```
Encontramos a probabilidade de aproximadamente 0,1

4.Considere como espaço de estados S = {0, 1, ... , 6} de uma Cadeia de Markov com matriz de transição
```{r}

estados4 = c("0", "1" , "2" , "3" , "4" , "5" , "6")
prob.T4 = matrix (c(1/2,0,1/8,1/4,1/8,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1/2,0,1/2,0,0,0,0,1/2,1/2,0,0,0,0,0,0,1/2,1/2),
                nrow=7, ncol=7, byrow=T,
                dimnames=list(estados4,estados4))
prob.T4 = new ("markovchain", states=estados4, transitionMatrix=prob.T4, name="Cadeia de Markoviana")

prob.T4
```
a)Determine quais estados sÃ£o transientes e quais recorrentes
```{r}
transientStates(prob.T4)

steadyStates(prob.T4)
```


Observamos que os estados de 1 a 6 são recorrentes, restando apenas o estado 0 como trasiente

b)Encontre $\rho_{0,y}$ para y=0,...,6.
```{r}
is.accessible(object = prob.T4, from = "0", to = "0")
is.accessible(object = prob.T4, from = "0", to = "1")
is.accessible(object = prob.T4, from = "0", to = "2")
is.accessible(object = prob.T4, from = "0", to = "3")
is.accessible(object = prob.T4, from = "0", to = "4")
is.accessible(object = prob.T4, from = "0", to = "5")
is.accessible(object = prob.T4, from = "0", to = "6")
firstPassage(prob.T4, 0, 6)
```

5.Num estudo com homens criminosos em Filadélfia descobriram que a probabilidade de que um tipo de ataque seja seguido por um outro tipo pode ser descrito pela seguinte matriz de transição.
```{r}
estados5 = c("Outro", "Injúria" , "Roubo" , "Dano" , "Misto")
prob.T5 = matrix (c(0.645,0.099,0.152,0.033,0.071,0.611,0.138,0.128,0.033,0.090,0.514,0.067,0.271,0.030,0.118,0.609,0.107,0.178,0.064,0.042,0.523,0.093,0.183,0.022,0.179),
                nrow=5, ncol=5, byrow=T,
                dimnames=list(estados5,estados5))
prob.T5 = new ("markovchain", states=estados5, transitionMatrix=prob.T5, name="Homens Criminosos")

prob.T5


```

a)Para um criminoso que comete roubo, qual é a probabilidade que o seu próximo crime também seja um roubo?
```{r}
roubou1 <- prob.T5^1
roubo <- 0.271
roubo
```
Conforme visto na tabela acima encontramos a probabilidade de aproximadamente 27%

b)Para um criminoso que comete roubo, qual é a probabilidade de que seu segundo crime depois do atual também seja um roubo?
```{r}
roubos2<- prob.T5^2
roubos2
```
Encontramos a probabilidade de aproximadamente 19%

c)Se essas tendências continuarem, quais são as probabilidades de longo prazo para cada tipo de crime?
```{r}
longoprazo <- steadyStates(prob.T5)
longoprazo
```

6.Considere uma Cadeia de Markov com espaço de estados S={0,1,2} e  matriz de probabilidades de transição
a)Mostre que esta cadeia tem uma única distribuição estacionária $\pi$ e encontre-a.
```{r}
estados6 = c("0", "1" , "2")
prob6 = matrix (c(0.4,0.4,0.2,0.3,0.4,0.3,0.2,0.4,0.4),
                nrow=3, ncol=3, byrow=T,
                dimnames=list(estados6,estados6))
prob6 = new ("markovchain", states=estados6, transitionMatrix=prob6, name="Cadeia de Markov 3")

prob6

steadyStates(prob6)
```
Podemos observar a distribuição estacionária sendo 0,3 / 0,4 / 0,3 para os estados 1 / 2 / 3 respectivamente.


7.Considere uma Cadeia de Markov sendo S={0,1,2,3,4} o espaço de estados e com matriz de probabilidades de transição
```{r}
estados7 = c("0", "1" , "2" , "3" , "4")
prob7 = matrix (c(0,1/3,2/3,0,0,0,0,0,1/4,3/4,0,0,0,1/4,3/4,1,0,0,0,0,1,0,0,0,0),
                nrow=5, ncol=5, byrow=T,
                dimnames=list(estados7,estados7))
prob7 = new ("markovchain", states=estados7, transitionMatrix=prob7, name="Matriz de Transição VII")

prob7

```

a)Mostre que esta é uma cadeia irredutível
```{r,echo=FALSE}
is.irreducible(prob7)
prob7
```

b)Encontre o período
```{r,echo=FALSE}
period(prob7)
```

c)Encontre a distribuição estacionária
```{r,echo=FALSE}
steadyStates(prob7)

```


